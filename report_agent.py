import os
import time
import json
import datetime
from typing import TypedDict, Optional
from langchain_openai import ChatOpenAI
# from langchain_community.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_core.prompts import ChatPromptTemplate
from langgraph.graph import StateGraph
from dotenv import load_dotenv
from transformers import AutoTokenizer, AutoModel
import torch
from docx import Document
from sqlalchemy import text
import asyncio
from db import AsyncSessionLocal
from sqlalchemy.orm import aliased
from decimal import Decimal
from langchain_chroma import Chroma

# --- ğŸ” ìƒíƒœ ì •ì˜ ---
class ProposalState(TypedDict, total=False):
    brand_name: Optional[str]
    brand_info: Optional[str]
    client_needs: Optional[str]
    recent_issues: Optional[str]
    sales_status: Optional[str]
    recommended_media: Optional[str]
    previous_campaigns: Optional[str]
    proposal_text: Optional[str]
    proposal_file_path: Optional[str]
    media_info: list

AgentState = ProposalState

# --- .env ì—ì„œ OPENAI API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸° ---
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

llm = ChatOpenAI(model="gpt-4o", openai_api_key=openai_api_key)

# --- HuggingFace ê¸°ë°˜ ì„ë² ë”© í´ë˜ìŠ¤ ---
class BERTSentenceEmbedding:
    def __init__(self, model_name="sentence-transformers/all-MiniLM-L6-v2"):
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModel.from_pretrained(model_name)

    def embed_documents(self, texts):
        return [self._embed(text) for text in texts]

    def embed_query(self, text):
        return self._embed(text)

    def _embed(self, text):
        inputs = self.tokenizer(text, return_tensors="pt", truncation=True, padding=True)
        with torch.no_grad():
            outputs = self.model(**inputs)
        cls_embedding = outputs.last_hidden_state[:, 0, :]
        return cls_embedding.squeeze(0).cpu().numpy()

embedding_function = BERTSentenceEmbedding()

# --- âœ… ê¸°ì¡´ ChromaDB ë¶ˆëŸ¬ì˜¤ê¸° ---
vectorstore = Chroma(
    collection_name="campaign_media_chroma_hf",
    embedding_function=embedding_function,
    persist_directory="./chroma_db2"
)

print("ê¸°ì¡´ ChromaDB ë¡œë“œ ì™„ë£Œ!")

# ë¹„ë™ê¸° DB ì¿¼ë¦¬ í•¨ìˆ˜
async def db_query_tool_async(query: str, params: dict = None):
    async with AsyncSessionLocal() as session:
        async with session.begin():
            result = await session.execute(text(query), params=params)
            return result.fetchall()

# ì›¹ ê²€ìƒ‰ ë„êµ¬
def web_search_tool(query: str) -> str:
    return f"[WEB SEARCH RESULT for: {query}]"

# Chroma DB ê²€ìƒ‰ ë„êµ¬
def vectordb_search_tool(query: str, vectorstore, top_k: int = 3) -> str:
    results = vectorstore.similarity_search(query, k=top_k)
    return "\n\n---\n\n".join([
        f"- {doc.page_content.strip()} \n[ì´ë¯¸ì§€ ë³´ê¸°]({doc.metadata.get('execution_image_url', '[ì´ë¯¸ì§€ ì—†ìŒ]')})"
        for doc in results
    ])

# ë¸Œëœë“œì™€ íŒë§¤ ê¸°ë¡ì„ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì¡°íšŒí•˜ëŠ” í•¨ìˆ˜
async def query_brand_and_sales_logs(brand_name: str):
    # ìˆ˜ì •ëœ ì¿¼ë¦¬: SQLAlchemyì—ì„œ íŒŒë¼ë¯¸í„° ë°”ì¸ë”©ì„ ì œëŒ€ë¡œ ì²˜ë¦¬í•˜ë„ë¡ ìˆ˜ì •
    brand_info = await db_query_tool_async(
        "SELECT * FROM brands WHERE brand_name = :brand_name", 
        {"brand_name": brand_name}
    )

    if not brand_info:
        return None, None

    brand_id = brand_info[0][0]  # ë¸Œëœë“œ ID ì¶”ì¶œ
    latest_sales_log = await db_query_tool_async(
        "SELECT * FROM sales_logs WHERE brand_id = :brand_id ORDER BY contact_time DESC LIMIT 1", 
        {"brand_id": brand_id}
    )
    print(brand_info)
    print(brand_id)
    print(latest_sales_log)
    return brand_info[0], latest_sales_log[0]

# ë¸Œëœë“œ ë° ìš”êµ¬ ì‚¬í•­ ë¶„ì„
async def analyze_brand_and_needs(state: ProposalState):
    brand_name = state["brand_name"]
    brand_row, sales_row = await query_brand_and_sales_logs(brand_name)
     
    if brand_row is None:
        raise ValueError(f"ë¸Œëœë“œ '{brand_name}' ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    # brand_rowì—ì„œ í•„ìš”í•œ ì •ë³´ ì¶”ì¶œ
    print(brand_row)
    print(sales_row)
    brand_information = {
        "brand_id": brand_row[0],
        "brand_name": brand_row[2],
        "sales_status": brand_row[6] or "ìƒíƒœ ì •ë³´ ì—†ìŒ",
        "recent_brand_issues": brand_row[10] or "ë¸Œëœë“œ ì´ìŠˆ ì •ë³´ ì—†ìŒ"
    }

    return {
        **state,
        "brand_info": brand_information,
        "client_needs": sales_row[10],
        "recent_issues": brand_information["recent_brand_issues"],
        "sales_status": brand_information["sales_status"]
    }
# ìœ ì‚¬í•œ ìº í˜ì¸ ì‚¬ë¡€ ê²€ìƒ‰
async def retrieve_previous_campaigns(state: ProposalState):
    client_needs = state.get("client_needs") or "ì˜¥ì™¸ ê´‘ê³  ì§‘í–‰ ì‚¬ë¡€"
    similar_cases = vectordb_search_tool(client_needs, vectorstore)
    return {**state, "previous_campaigns": similar_cases}

async def db_query_tool_async_b(query: str, params: dict = None):
    async with AsyncSessionLocal() as session:
        async with session.begin():
            result = await session.execute(text(query), params or {})
            rows = result.fetchall()
            return [dict(row._mapping) for row in rows]

# ë§¤ì²´ ì¶”ì²œ
async def recommend_media(state: ProposalState):
    client_needs = state.get("client_needs") or ""
    db_results = await db_query_tool_async_b("SELECT * FROM medias WHERE quantity > 0;")
    if not db_results:
        raise ValueError("ì‚¬ìš© ê°€ëŠ¥í•œ ë§¤ì²´ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    media_json = json.dumps(db_results, ensure_ascii=False, default=lambda o: float(o) if isinstance(o, Decimal) else str(o))
    prompt = f"""
        ë‹¹ì‹ ì€ ì˜¥ì™¸ ê´‘ê³  ì „ë¬¸ ëŒ€í–‰ì‚¬ì˜ ì „ëµ ê¸°íšìì…ë‹ˆë‹¤.
        ë‹¤ìŒ ë¸Œëœë“œì˜ ê³ ê° ìš”êµ¬ì‚¬í•­ê³¼ ìœ ì‚¬ ì§‘í–‰ ì‚¬ë¡€ë¥¼ ê³ ë ¤í•˜ì—¬ ê°€ì¥ ì í•©í•œ ì˜¥ì™¸ ê´‘ê³  ë§¤ì²´ 3ê°€ì§€ë¥¼ ì¶”ì²œí•´ì•¼ í•©ë‹ˆë‹¤.

        - ë¸Œëœë“œ ê³ ê° ìš”êµ¬ì‚¬í•­: {state.get('client_needs')}
        - ìœ ì‚¬ ì§‘í–‰ ì‚¬ë¡€ ìš”ì•½: {state.get('previous_campaigns')}

        ë‹¤ìŒì€ ì‚¬ìš© ê°€ëŠ¥í•œ ë§¤ì²´ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤:
        {media_json}
    """
    recommendation = await llm.ainvoke(prompt)
    return {**state, "recommended_media": recommendation.content, "media_info": db_results}

def generate_proposal(state: ProposalState):
    import datetime
    import re
    doc = Document()
    doc.add_heading(f"{state['brand_name']} ì˜¥ì™¸ ê´‘ê³  ì œì•ˆì„œ", level=1)

    doc.add_heading("1. ê³ ê°ì‚¬ ì •ë³´", level=2)
    brand_info = state["brand_info"]
    if isinstance(brand_info, dict):
        for key, value in brand_info.items():
            doc.add_paragraph(f"- {key}: {value}")

    doc.add_heading("2. ìº í˜ì¸ ëª©í‘œ", level=2)
    client_needs = state["client_needs"]
    for item in re.split(r",|Â·|â€¢", client_needs):
        if item.strip():
            doc.add_paragraph(f"- {item.strip()}")

    doc.add_heading("3. ìœ ì‚¬ ì§‘í–‰ ì‚¬ë¡€", level=2)
    previous_campaigns = state["previous_campaigns"]
    cases = previous_campaigns.split("\n\n---\n\n")
    for idx, case in enumerate(cases, 1):
        doc.add_paragraph(f"- ì‚¬ë¡€ {idx}: {case}")

    doc.add_heading("4. ì¶”ì²œë§¤ì²´ ë° ì§‘í–‰ê³„íš", level=2)
    doc.add_paragraph(state["recommended_media"])

    doc.add_heading("5. ê²°ë¡ ", level=2)
    prompt = ChatPromptTemplate.from_template("""
    ë¸Œëœë“œëª…: {brand_name}
    ìº í˜ì¸ ëª©í‘œ: {client_needs}
    ì¶”ì²œ ë§¤ì²´: {recommended_media}

    ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì œì•ˆì„œì˜ ë§ˆë¬´ë¦¬ ê²°ë¡  ë¶€ë¶„ì„ ì‘ì„±í•˜ì„¸ìš”.
    """)
    chain = prompt | llm
    conclusion = chain.invoke(state).content
    doc.add_paragraph(conclusion)

    now = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    file_name = f"{state['brand_name']}_ì œì•ˆì„œ_{now}.docx"
    doc.save(file_name)

    return {**state, "proposal_text": conclusion, "proposal_file_path": file_name}

# ê·¸ë˜í”„ êµ¬ì„±
graph = StateGraph(ProposalState)
graph.add_node("AnalyzeBrandAndNeeds", analyze_brand_and_needs)
graph.add_node("RecommendMedia", recommend_media)
graph.add_node("RetrievePreviousCampaigns", retrieve_previous_campaigns)
graph.add_node("GenerateProposal", generate_proposal)
graph.set_entry_point("AnalyzeBrandAndNeeds")
graph.add_edge("AnalyzeBrandAndNeeds", "RetrievePreviousCampaigns")
graph.add_edge("RetrievePreviousCampaigns", "RecommendMedia")
graph.add_edge("RecommendMedia", "GenerateProposal")
graph.set_finish_point("GenerateProposal")
proposal_graph = graph.compile()

# --- ğŸš€ ì‹¤í–‰ ---
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument("--brand", required=True, help="ë¸Œëœë“œëª… (ì˜ˆ: ìœ ë‹ˆí´ë¡œì½”ë¦¬ì•„)")
    args = parser.parse_args()

    initial_state = {"brand_name": args.brand}
    final_state = asyncio.run(proposal_graph.ainvoke(initial_state))

    import sys
    print("ìµœì¢… ì œì•ˆì„œ:\n", file=sys.stderr)
    print(final_state["proposal_text"], file=sys.stderr)
    print(f"ì œì•ˆì„œ Word íŒŒì¼ ê²½ë¡œ: {final_state['proposal_file_path']}", file=sys.stderr)


    result = {
        "success": True,
        "brand": initial_state["brand_name"],
        "file_path": final_state["proposal_file_path"],
        "created_at": time.strftime("%Y-%m-%d %H:%M:%S")
    }
    print(json.dumps(result))