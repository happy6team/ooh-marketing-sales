from typing import TypedDict, Optional
from langchain_core.prompts import ChatPromptTemplate
from langgraph.graph import StateGraph
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
import mysql.connector
from langchain_community.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from docx import Document
import pandas as pd
import os
from docx.shared import Inches
from transformers import AutoTokenizer, AutoModel
import torch
import json
from decimal import Decimal
import sys
import time

# --- ğŸ” ìƒíƒœ ì •ì˜ ---
class ProposalState(TypedDict, total=False):
    brand_name: Optional[str]
    brand_info: Optional[str]
    client_needs: Optional[str]
    recent_issues: Optional[str]
    sales_status: Optional[str]
    recommended_media: Optional[str]
    previous_campaigns: Optional[str]
    proposal_text: Optional[str]
    proposal_file_path: Optional[str]
    media_info: list

AgentState = ProposalState

# --- .env ì—ì„œ OPENAI API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸° ---
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

llm = ChatOpenAI(model="gpt-4o", openai_api_key=openai_api_key)

# --- HuggingFace ê¸°ë°˜ ì„ë² ë”© í´ë˜ìŠ¤ ---
class BERTSentenceEmbedding:
    def __init__(self, model_name="sentence-transformers/all-MiniLM-L6-v2"):
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModel.from_pretrained(model_name)

    def embed_documents(self, texts):
        return [self._embed(text) for text in texts]

    def embed_query(self, text):
        return self._embed(text)

    def _embed(self, text):
        inputs = self.tokenizer(text, return_tensors="pt", truncation=True, padding=True)
        with torch.no_grad():
            outputs = self.model(**inputs)
        cls_embedding = outputs.last_hidden_state[:, 0, :]
        return cls_embedding.squeeze(0).cpu().numpy()

embedding_function = BERTSentenceEmbedding()

# --- âœ… ê¸°ì¡´ ChromaDB ë¶ˆëŸ¬ì˜¤ê¸° ---
vectorstore = Chroma(
    collection_name="campaign_media_chroma_hf",
    embedding_function=embedding_function,
    persist_directory="./chroma_db2"
)

print("ê¸°ì¡´ ChromaDB ë¡œë“œ ì™„ë£Œ!", file=sys.stderr)

def db_query_tool(query: str):
    load_dotenv()
    conn = mysql.connector.connect(
        host=os.getenv("DB_HOST"),
        user=os.getenv("DB_USER"),
        password=os.getenv("DB_PASSWORD"),
        database=os.getenv("DB_NAME")
    )
    cursor = conn.cursor(dictionary=True)
    cursor.execute(query)
    results = cursor.fetchall()
    cursor.close()
    conn.close()
    return results

def web_search_tool(query: str) -> str:
    return f"[WEB SEARCH RESULT for: {query}]"

def vectordb_search_tool(query: str, vectorstore, top_k: int = 3) -> str:
    results = vectorstore.similarity_search(query, k=top_k)
    combined_results = []
    for doc in results:
        content = doc.page_content
        content_lines = [f"- {line.strip()}" for line in content.split(",")]
        content_formatted = "\n".join(content_lines)
        image_url = doc.metadata.get("execution_image_url", "")
        if image_url.startswith("/images/"):
            image_url = "./" + image_url.lstrip("/")
        elif image_url == "":
            image_url = "[ì´ë¯¸ì§€ ì—†ìŒ]"
        content_with_image = f"{content_formatted}\n[ì´ë¯¸ì§€ ë³´ê¸°]({image_url})"
        combined_results.append(content_with_image)
    return "\n\n---\n\n".join(combined_results)

def query_brand_and_sales_logs(brand_name: str):
    load_dotenv()
    conn = mysql.connector.connect(
        host=os.getenv("DB_HOST"),
        user=os.getenv("DB_USER"),
        password=os.getenv("DB_PASSWORD"),
        database=os.getenv("DB_NAME")
    )
    cursor = conn.cursor(dictionary=True)
    cursor.execute("""SELECT * FROM brands WHERE brand_name = %s""", (brand_name,))
    brand_info = cursor.fetchone()

    if not brand_info:
        cursor.close()
        conn.close()
        return None, None

    brand_id = brand_info["brand_id"]
    cursor.execute("""SELECT * FROM sales_logs WHERE brand_id = %s ORDER BY contact_time DESC LIMIT 1""", (brand_id,))
    latest_sales_log = cursor.fetchone()
    cursor.close()
    conn.close()

    return brand_info, latest_sales_log

def analyze_brand_and_needs(state: ProposalState):
    brand_name = state["brand_name"]
    brand_info, latest_sales_log = query_brand_and_sales_logs(brand_name)
    if not brand_info:
        raise ValueError(f"ë¸Œëœë“œ '{brand_name}' ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    client_needs = latest_sales_log["client_needs_summary"] if latest_sales_log else "ìµœê·¼ ê³ ê° ìš”êµ¬ì‚¬í•­ ì •ë³´ ì—†ìŒ"
    recent_issues = brand_info.get("recent_brand_issues") or "ë¸Œëœë“œ ì´ìŠˆ ì •ë³´ ì—†ìŒ"
    sales_status = brand_info.get("sales_status") or "ìƒíƒœ ì •ë³´ ì—†ìŒ"

    return {
        **state,
        "brand_info": brand_info,
        "client_needs": client_needs,
        "recent_issues": recent_issues,
        "sales_status": sales_status
    }

def retrieve_previous_campaigns(state: ProposalState):
    client_needs = state.get("client_needs") or "ì˜¥ì™¸ ê´‘ê³  ì§‘í–‰ ì‚¬ë¡€"
    similar_cases = vectordb_search_tool(client_needs, vectorstore)
    return {**state, "previous_campaigns": similar_cases}

def recommend_media(state: ProposalState):
    client_needs = state.get("client_needs") or ""
    db_results = db_query_tool("SELECT * FROM medias WHERE quantity > 0;")
    if not db_results:
        raise ValueError("ì‚¬ìš© ê°€ëŠ¥í•œ ë§¤ì²´ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
    media_info = db_results

    media_json = json.dumps(db_results, ensure_ascii=False, default=lambda o: float(o) if isinstance(o, Decimal) else str(o))
    prompt = f"""
        ë‹¹ì‹ ì€ ì˜¥ì™¸ ê´‘ê³  ì „ë¬¸ ëŒ€í–‰ì‚¬ì˜ ì „ëµ ê¸°íšìì…ë‹ˆë‹¤.
        ë‹¤ìŒ ë¸Œëœë“œì˜ ê³ ê° ìš”êµ¬ì‚¬í•­ê³¼ ìœ ì‚¬ ì§‘í–‰ ì‚¬ë¡€ë¥¼ ê³ ë ¤í•˜ì—¬ ê°€ì¥ ì í•©í•œ ì˜¥ì™¸ ê´‘ê³  ë§¤ì²´ 3ê°€ì§€ë¥¼ ì¶”ì²œí•´ì•¼ í•©ë‹ˆë‹¤.

        - ë¸Œëœë“œ ê³ ê° ìš”êµ¬ì‚¬í•­: {state.get('client_needs')}
        - ìœ ì‚¬ ì§‘í–‰ ì‚¬ë¡€ ìš”ì•½: {state.get('previous_campaigns')}

        ë‹¤ìŒì€ ì‚¬ìš© ê°€ëŠ¥í•œ ë§¤ì²´ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤:
        {media_json}
    """
    recommendation = llm.invoke(prompt)
    recommendation_text = recommendation.content

    return {**state, "recommended_media": recommendation_text, "media_info": media_info}

def generate_proposal(state: ProposalState):
    import datetime
    import re
    from docx import Document
    from docx.shared import Inches
    from langchain.prompts import ChatPromptTemplate

    doc = Document()
    doc.add_heading(f"{state['brand_name']} ì˜¥ì™¸ ê´‘ê³  ì œì•ˆì„œ", level=1)
    doc.add_paragraph("") 

    # --- 1. ê³ ê°ì‚¬ ì •ë³´ ---
    doc.add_heading("1. ê³ ê°ì‚¬ ì •ë³´", level=2)
    brand_info = state["brand_info"]

    # brand_infoê°€ dict í˜•íƒœë¼ë©´:
    if isinstance(brand_info, dict):
        for key, value in brand_info.items():
            doc.add_paragraph(f"- {key}: {value}")
    else:
        # CSVì²˜ëŸ¼ í•œ ì¤„ë¡œ ë“¤ì–´ì™”ì„ ê²½ìš° â†’ í‚¤:ê°’ í˜•íƒœë¡œ ì¤„ë°”ê¿ˆ
        lines = re.split(r",|\t", brand_info)
        for line in lines:
            if ':' in line:
                doc.add_paragraph(f"- {line.strip()}")
            elif line.strip():
                doc.add_paragraph(f"- {line.strip()}")

    # --- 2. ìº í˜ì¸ ëª©í‘œ ---
    doc.add_paragraph("") 
    doc.add_heading("2. ìº í˜ì¸ ëª©í‘œ", level=2)
    client_needs = state["client_needs"]

    # ì‰¼í‘œë¡œ êµ¬ë¶„ â†’ ë¬¸ì¥ë³„ë¡œ ì¶œë ¥
    for item in re.split(r",|Â·|â€¢", client_needs):
        if item.strip():
            doc.add_paragraph(f"- {item.strip()}")

    # --- 3. ìœ ì‚¬ ì§‘í–‰ ì‚¬ë¡€ ---
    doc.add_heading("3. ìœ ì‚¬ ì§‘í–‰ ì‚¬ë¡€", level=2)
    previous_campaigns = state["previous_campaigns"]

    cases = previous_campaigns.split("\n\n---\n\n")
    filtered_cases = []
    for idx, case in enumerate(cases, start=1):
        if "ì‚¬ë¡€ 3" in case:
            continue  # ì‚¬ë¡€ 3 ì œì™¸

        # ì´ë¯¸ì§€ URL ì¶”ì¶œ
        image_url = None
        image_match = re.search(r"\[ì´ë¯¸ì§€ ë³´ê¸°\]\((.*?)\)", case)
        if image_match:
            image_url = image_match.group(1).strip()

        # í…ìŠ¤íŠ¸ì—ì„œ [ì´ë¯¸ì§€ ë³´ê¸°] ë¶€ë¶„ ì‚­ì œ
        case_text = re.sub(r"\[ì´ë¯¸ì§€ ë³´ê¸°\]\(.*?\)", "", case).strip()
        filtered_cases.append((f"- ì‚¬ë¡€ {idx}\n{case_text}", image_url))

    # âœ… 3í–‰ 2ì—´ì§œë¦¬ í‘œ ìƒì„± (í–‰ = ì‚¬ë¡€ ê°œìˆ˜, ì—´ = 2)
    table = doc.add_table(rows=len(filtered_cases), cols=2)
    table.style = 'Table Grid'

    for row_idx, (case_text, image_url) in enumerate(filtered_cases):
        # ì™¼ìª½ ì…€: ì‚¬ë¡€ ë‚´ìš©
        table.cell(row_idx, 0).text = case_text

        # ì˜¤ë¥¸ìª½ ì…€: ì´ë¯¸ì§€ ë˜ëŠ” í…ìŠ¤íŠ¸
        cell_image = table.cell(row_idx, 1)
        if image_url and image_url.endswith((".jpg", ".png")):
            try:
                run = cell_image.paragraphs[0].add_run()
                run.add_picture(image_url, width=Inches(2.5))
            except Exception as e:
                cell_image.text = f"ì´ë¯¸ì§€ ì‚½ì… ì‹¤íŒ¨ ({e})"
        else:
            cell_image.text = "ì´ë¯¸ì§€ ì—†ìŒ"

    # --- 4. ì¶”ì²œë§¤ì²´ ë° ì§‘í–‰ê³„íš ---
    doc.add_paragraph("") 
    doc.add_heading("4. ì¶”ì²œë§¤ì²´ ë° ì§‘í–‰ê³„íš", level=2)

    recommended_media = state["recommended_media"]
    if hasattr(recommended_media, "content"):
        recommended_media_text = recommended_media.content
    else:
        recommended_media_text = recommended_media

    media_rows = state.get("media_info", [])
    media_image_map = {row["media_name"].strip().lower(): row["image_day_url"] for row in media_rows}

    # â­ "1.", "2.", "3." ìœ¼ë¡œ ì‹œì‘í•˜ëŠ” ì¶”ì²œ ë§¤ì²´ ë¸”ë¡ë§Œ ì¶”ì¶œ
    lines = recommended_media_text.split("\n")
    media_blocks = []
    current_block = ""

    for line in lines:
        clean_line = re.sub(r"\*+", "", line.strip())
        if re.match(r"^\d+\.", clean_line):  # "1.", "2.", "3." ë§¤ì²´ ë²ˆí˜¸ë¡œ ì‹œì‘
            if current_block:
                media_blocks.append(current_block.strip())
            current_block = clean_line
        elif current_block:
            current_block += "\n" + clean_line
    # ë§ˆì§€ë§‰ ë¸”ë¡ ì¶”ê°€
    if current_block:
        media_blocks.append(current_block.strip())

    # â­ ìƒìœ„ 3ê°œ ë§¤ì²´ë§Œ ì‚¬ìš©
    selected_media_blocks = media_blocks[:3]

    # âœ… 3í–‰ 2ì—´ì§œë¦¬ í‘œ ìƒì„±
    table = doc.add_table(rows=3, cols=2)
    table.style = 'Table Grid'

    for idx, block in enumerate(selected_media_blocks):
        # ë§¤ì²´ëª… ì¶”ì¶œ
        name_match = re.search(r"ë§¤ì²´ëª…\s*[:ï¼š]\s*(.+)", block)
        if name_match:
            media_name = name_match.group(1).strip()
        else:
            # ğŸ” ì˜ˆ: "ë§¤ì²´ id: 14 - n.square ê°•ë‚¨ëŒ€ë¡œ"
            name_match = re.search(r"ë§¤ì²´ id\s*[:ï¼š]?\s*\d+\s*-\s*(.+)", block)
            if name_match:
                media_name = name_match.group(1).strip()
            else:
                # ğŸ” ì˜ˆ: "1. n.square ê°•ë‚¨ëŒ€ë¡œ"
                name_match = re.search(r"^\d+\.\s*(.+)", block)
                media_name = name_match.group(1).strip() if name_match else "ì¶”ì²œ ë§¤ì²´"

        media_name_clean = media_name.replace("*", "").strip().lower()
        media_name_clean = re.sub(r"\(media id: \d+\)", "", media_name_clean).strip()
        image_url = media_image_map.get(media_name_clean)
        
        with open("media_debug_log.txt", "a", encoding="utf-8") as log_file:
                log_file.write(f"[{idx}] ë§¤ì²´ëª…: {media_name_clean} â†’ ì´ë¯¸ì§€ ê²½ë¡œ: {image_url}\n")

        if image_url and image_url.startswith("/images/"):
            image_url = "./images/" + image_url[len("/images/"):]

        # ì™¼ìª½ ì…€: ë§¤ì²´ ì„¤ëª…
        table.cell(idx, 0).text = block

        # ì˜¤ë¥¸ìª½ ì…€: ë§¤ì²´ ì´ë¯¸ì§€
        cell_image = table.cell(idx, 1)
        # ì´ë¯¸ì§€ ì‚½ì…
        if image_url and image_url.endswith((".jpg", ".png")):
            try:
                run = cell_image.paragraphs[0].add_run()
                run.add_picture(image_url, width=Inches(3))
            except Exception as e:
                cell_image.text = f"ì´ë¯¸ì§€ ì‚½ì… ì‹¤íŒ¨ ({e})"
        else:
            cell_image.text = "ì´ë¯¸ì§€ ì—†ìŒ"

    # í˜¹ì‹œ 3ê°œë³´ë‹¤ ì ìœ¼ë©´ ë‚˜ë¨¸ì§€ ë¹„ì›Œë†“ê¸°
    for idx in range(len(selected_media_blocks), 3):
        table.cell(idx, 0).text = ""
        table.cell(idx, 1).text = ""

    # --- 5. ê²°ë¡  (LLM ì‚¬ìš©) ---
    doc.add_paragraph("") 
    doc.add_heading("5. ê²°ë¡ ", level=2)

    # LLM í”„ë¡¬í”„íŠ¸
    prompt = ChatPromptTemplate.from_template("""
    ë¸Œëœë“œëª…: {brand_name}
    ìº í˜ì¸ ëª©í‘œ: {client_needs}
    ì¶”ì²œ ë§¤ì²´: {recommended_media}

    ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì œì•ˆì„œì˜ ë§ˆë¬´ë¦¬ ê²°ë¡  ë¶€ë¶„ì„ ì‘ì„±í•˜ì„¸ìš”.
    """)
    chain = prompt | llm
    conclusion = chain.invoke(state).content

    doc.add_paragraph(conclusion)

    now = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    file_name = f"{state['brand_name']}_ì œì•ˆì„œ_{now}.docx"
    doc.save(file_name)

    return {**state, "proposal_text": conclusion, "proposal_file_path": file_name}

# --- ğŸ”— ê·¸ë˜í”„ êµ¬ì„± ---
graph = StateGraph(ProposalState)
graph.add_node("AnalyzeBrandAndNeeds", analyze_brand_and_needs)
graph.add_node("RecommendMedia", recommend_media)
graph.add_node("RetrievePreviousCampaigns", retrieve_previous_campaigns)
graph.add_node("GenerateProposal", generate_proposal)

graph.set_entry_point("AnalyzeBrandAndNeeds")
graph.add_edge("AnalyzeBrandAndNeeds", "RetrievePreviousCampaigns")
graph.add_edge("RetrievePreviousCampaigns", "RecommendMedia")
graph.add_edge("RecommendMedia", "GenerateProposal")
graph.set_finish_point("GenerateProposal")

proposal_graph = graph.compile()

# --- ğŸš€ ì‹¤í–‰ ---
if __name__ == "__main__":
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument("--brand", required=True, help="ë¸Œëœë“œëª… (ì˜ˆ: ìœ ë‹ˆí´ë¡œì½”ë¦¬ì•„)")
    args = parser.parse_args()

    initial_state = {
        "brand_name": args.brand
    }

    final_state = proposal_graph.invoke(initial_state)

    print("ìµœì¢… ì œì•ˆì„œ:\n", file=sys.stderr)
    print(final_state["proposal_text"], file=sys.stderr)
    print(f"ì œì•ˆì„œ Word íŒŒì¼ ê²½ë¡œ: {final_state['proposal_file_path']}", file=sys.stderr)

    result = {
        "success": True,
        "brand": initial_state["brand_name"],
        "file_path": final_state["proposal_file_path"],
        "created_at": time.strftime("%Y-%m-%d %H:%M:%S")
    }
    print(json.dumps(result))