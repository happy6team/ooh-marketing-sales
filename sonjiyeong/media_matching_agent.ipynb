{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d19f9975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7eeb4aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "from typing import Annotated, TypedDict\n",
    "import ast\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "137428e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/OoHMarketingSalse/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Step 1: Load CSV data\n",
    "file_path = \"data/media.csv\"  # This should be the uploaded CSV file\n",
    "df = pd.read_csv(file_path, header=None)\n",
    "\n",
    "# Step 2: Define column names manually since no header in the file\n",
    "df.columns = [\n",
    "    \"media_id\", \"media_name\", \"location\", \"size\", \"duration\", \"media_type\",\n",
    "    \"operating_hours\", \"is_digital\", \"slot_count\", \"is_available\", \"unit_price\",\n",
    "    \"location_description\", \"image_day\", \"image_night\", \"image_map\",\n",
    "    \"population_target\", \"media_characteristics\", \"case_examples\"\n",
    "]\n",
    "\n",
    "# Step 3: Prepare embedding model using HuggingFace (MiniLM)\n",
    "class BERTSentenceEmbedding:\n",
    "    def __init__(self, model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        return [self._embed(text) for text in texts]\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        return self._embed(text)\n",
    "\n",
    "    def _embed(self, text):\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze(0)\n",
    "        return cls_embedding.cpu().numpy()\n",
    "\n",
    "embedding_function = BERTSentenceEmbedding()\n",
    "\n",
    "# Step 4: Construct documents for Chroma\n",
    "def build_text(row):\n",
    "    return f\"\"\"\n",
    "    위치 설명: {row['location_description']}\n",
    "    타겟: {row['population_target']}\n",
    "    매체 특징: {row['media_characteristics']}\n",
    "    집행 사례: {row['case_examples']}\n",
    "    \"\"\"\n",
    "\n",
    "docs = []\n",
    "for i, row in df.iterrows():\n",
    "    doc = Document(\n",
    "        page_content=build_text(row),\n",
    "        metadata={\n",
    "            \"media_id\": str(row[\"media_id\"]),\n",
    "            \"media_name\": row[\"media_name\"],\n",
    "            \"location\": row[\"location\"],\n",
    "            \"media_type\": row[\"media_type\"],\n",
    "            \"population_target\": row[\"population_target\"],\n",
    "            \"media_characteristics\": row[\"media_characteristics\"],\n",
    "            \"case_examples\": row[\"case_examples\"]\n",
    "        }\n",
    "    )\n",
    "    docs.append(doc)\n",
    "\n",
    "# Step 5: Store in Chroma\n",
    "chroma_collection = Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embedding_function,\n",
    "    collection_name=\"media\",\n",
    "    persist_directory=\"./chroma_media\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3803a4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x8/x9mhzs_j0yx8btgk3t9m0vvc0000gn/T/ipykernel_2183/570867232.py:1: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  chroma_collection.persist()\n"
     ]
    }
   ],
   "source": [
    "chroma_collection.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23744721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장된 문서 수: 51\n"
     ]
    }
   ],
   "source": [
    "print(\"저장된 문서 수:\", chroma_collection._collection.count())  # 또는 chroma_collection._collection.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15aa70c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# (전제) 임베딩 함수 정의되어 있음\n",
    "embedding_function = BERTSentenceEmbedding()\n",
    "\n",
    "# ✅ LLM 및 벡터DB 연결\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "chroma_collection = Chroma(\n",
    "    collection_name=\"media\",\n",
    "    embedding_function=embedding_function,\n",
    "    persist_directory=\"./chroma_media\"\n",
    ")\n",
    "\n",
    "# ✅ 출력 구조 정의\n",
    "class MatchingAgent(TypedDict):\n",
    "    brand: dict\n",
    "    top_3_matches: list[dict]\n",
    "    matching_reason: str\n",
    "    sales_talking_points: list[str]\n",
    "\n",
    "# ✅ 에이전트 정의\n",
    "def media_matcher_agent(brand_name: str, recent_issue: str, brand_description: str) -> MatchingAgent:\n",
    "    query_text = f\"{recent_issue} / {brand_description}\"\n",
    "    results = chroma_collection.similarity_search_with_score(query_text, k=10)  # 넉넉하게 검색\n",
    "\n",
    "    # 중복 제거된 매체 3개만 추출\n",
    "    seen_ids = set()\n",
    "    top_matches = []\n",
    "    for doc, _ in results:\n",
    "        meta = doc.metadata\n",
    "        if meta[\"media_id\"] in seen_ids:\n",
    "            continue\n",
    "        seen_ids.add(meta[\"media_id\"])\n",
    "        reason = f\"{meta['population_target']}을 타겟으로 하며, '{meta['media_characteristics']}' 특성을 가짐. '{meta['case_examples']}' 등 유사 캠페인 존재.\"\n",
    "        top_matches.append({\n",
    "            \"rank\": len(top_matches) + 1,\n",
    "            \"media_id\": meta[\"media_id\"],\n",
    "            \"media_name\": meta[\"media_name\"],\n",
    "            \"location\": meta[\"location\"],\n",
    "            \"media_type\": meta[\"media_type\"],\n",
    "            \"individual_reason\": reason\n",
    "        })\n",
    "        if len(top_matches) == 3:\n",
    "            break\n",
    "\n",
    "    # ✅ 매칭 이유 생성 프롬프트\n",
    "    match_prompt = f\"\"\"\n",
    "    브랜드명: {brand_name}\n",
    "    최근 마케팅 이슈: {recent_issue}\n",
    "    브랜드 설명: {brand_description}\n",
    "    추천된 매체:\n",
    "    1. {top_matches[0]['media_name']} ({top_matches[0]['location']}) - {top_matches[0]['individual_reason']}\n",
    "    2. {top_matches[1]['media_name']} ({top_matches[1]['location']}) - {top_matches[1]['individual_reason']}\n",
    "    3. {top_matches[2]['media_name']} ({top_matches[2]['location']}) - {top_matches[2]['individual_reason']}\n",
    "\n",
    "    위 정보를 바탕으로, 이 3개 매체가 왜 이 브랜드에 적합한지 요약해줘.\n",
    "    포멀하고 간결한 문장으로 1~2줄로 작성해줘.\n",
    "    \"\"\"\n",
    "    matching_reason = llm.invoke(match_prompt).content.strip()\n",
    "\n",
    "    # ✅ 세일즈 포인트 생성 프롬프트\n",
    "    sales_prompt = f\"\"\"\n",
    "    브랜드: {brand_name}\n",
    "    이슈: {recent_issue}\n",
    "    브랜드 설명: {brand_description}\n",
    "    추천 매체: {', '.join([m['media_name'] for m in top_matches])}\n",
    "\n",
    "    광고주에게 제안할 세일즈 문장을 3줄로 작성해줘.\n",
    "    - 1줄: 이슈 기반 축하 + 제안 개요\n",
    "    - 2줄: 추천 매체를 활용한 전략 제안\n",
    "    - 3줄: 브랜드 효과 강조\n",
    "    모든 문장은 B2B 세일즈 스타일로 포멀하게 써줘.\n",
    "    \"\"\"\n",
    "    sales_points = llm.invoke(sales_prompt).content.strip().split(\"\\n\")\n",
    "    sales_points = [line.strip(\"- \").strip() for line in sales_points if line.strip()][:3]\n",
    "\n",
    "    # ✅ 최종 반환\n",
    "    return {\n",
    "        \"brand\": {\n",
    "            \"name\": brand_name,\n",
    "            \"recent_issue\": recent_issue,\n",
    "            \"target_audience\": brand_description\n",
    "        },\n",
    "        \"top_3_matches\": top_matches,\n",
    "        \"matching_reason\": matching_reason,\n",
    "        \"sales_talking_points\": sales_points\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "663f2985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brand': {'name': '더바넷',\n",
       "  'recent_issue': '2025년 3월 9일: 서울 잠실 롯데월드몰에 국내 첫 팝업스토어 오픈',\n",
       "  'target_audience': '2021년 론칭한 캐주얼 브랜드로, 20·30세대 고객에게 가장 트렌디한 브랜드로 손꼽히며, 가방과 모자, 액세서리를 포함한 다양한 상품을 선보인다.'},\n",
       " 'top_3_matches': [{'rank': 1,\n",
       "   'media_id': '17',\n",
       "   'media_name': '가로변 버스쉘터 강남대로',\n",
       "   'location': '서울시 강남구 강남대로 일대',\n",
       "   'media_type': '버스정류장 쉘터 광고',\n",
       "   'individual_reason': \"버스 이용객, 보행자, 전 연령층, 특히 출퇴근 시간대 직장인을 타겟으로 하며, '서울 전 지역 2100여 기가 설치된 생활밀착형 매체로, 지역 타겟팅 용이' 특성을 가짐. '음료 브랜드 시즌 캠페인(2023년 여름), 배달앱 신규 서비스(2024년 초)' 등 유사 캠페인 존재.\"},\n",
       "  {'rank': 2,\n",
       "   'media_id': '12',\n",
       "   'media_name': '홍대입구역 스칼렛 전광판',\n",
       "   'location': '서울시 마포구 양화로 148',\n",
       "   'media_type': '벽면형 세로 사이니지',\n",
       "   'individual_reason': \"대학생, MZ세대, 예술인, 외국인 관광객, 20-30대, 28개 정류장 쇼핑/유흥/대학 등 상권 발달을 타겟으로 하며, '눈에 띄는 건물 외벽으로 인해 더욱 자연스럽게 시선이 집중되며, 홍대 문화의 중심지' 특성을 가짐. '카카오 신규 서비스 런칭(2023년 가을), 애플 아이폰 신제품 출시(2023년 겨울)' 등 유사 캠페인 존재.\"},\n",
       "  {'rank': 3,\n",
       "   'media_id': '2',\n",
       "   'media_name': '서울 고속버스터미널 (경부선)',\n",
       "   'location': '서울시 서초구 신반포로 194',\n",
       "   'media_type': '옥상형 가로 사이니지',\n",
       "   'individual_reason': \"전국 각지 방문객 및 지역 거주자, 10-60대 전 연령층, 일 유동인구 36만명을 타겟으로 하며, '24시간 운영되는 교통 허브로, 전국 단위 광고 캠페인에 적합한 매체' 특성을 가짐. '신세계백화점 시즌 세일(2024년 1분기), 롯데관광 제주도 패키지(2023년 여름)' 등 유사 캠페인 존재.\"}],\n",
       " 'matching_reason': '더바넷의 팝업스토어 오픈과 관련하여, 강남대로의 가로변 버스쉘터는 직장인 대상의 생활 밀착형 매체로 적합하며, 홍대입구역 스칼렛 전광판은 MZ세대와 외국인 관광객을 효과적으로 타겟팅할 수 있어 브랜드 인지도 향상에 기여할 것입니다. 또한, 서울 고속버스터미널은 전국 각지의 방문객을 대상으로 하는 광고에 적합하여 브랜드의 넓은 도달 범위를 지원합니다.',\n",
       " 'sales_talking_points': ['더바넷의 서울 잠실 롯데월드몰 팝업스토어 오픈을 진심으로 축하드립니다. 고객의 유입과 브랜드 인지도를 극대화하기 위해, 강남대로 가로변 버스쉘터 및 홍대입구역 스칼렛 전광판과 서울 고속버스터미널을 활용한 집중 광고 전략을 제안합니다. 이러한 전략적 매체 선택은 20·30세대 고객층의 높은 주목도를 이끌어내며, 브랜드의 트렌디한 이미지 강화를 통해 긍정적인 효과를 가져올 것입니다.']}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = media_matcher_agent(\n",
    "    brand_name=\"더바넷\",\n",
    "    recent_issue=\"2025년 3월 9일: 서울 잠실 롯데월드몰에 국내 첫 팝업스토어 오픈\",\n",
    "    brand_description=\"2021년 론칭한 캐주얼 브랜드로, 20·30세대 고객에게 가장 트렌디한 브랜드로 손꼽히며, 가방과 모자, 액세서리를 포함한 다양한 상품을 선보인다.\"\n",
    ")\n",
    "\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OoHMarketingSalse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
