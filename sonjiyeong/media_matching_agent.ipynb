{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d19f9975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7eeb4aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_teddynote.tools.tavily import TavilySearch\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.messages import HumanMessage\n",
    "from typing import Annotated, TypedDict\n",
    "import ast\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "137428e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.documents import Document\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Step 1: Load CSV data\n",
    "file_path = \"data/media.csv\"  # This should be the uploaded CSV file\n",
    "df = pd.read_csv(file_path, header=None)\n",
    "\n",
    "# Step 2: Define column names manually since no header in the file\n",
    "df.columns = [\n",
    "    \"media_id\", \"media_name\", \"location\", \"size\", \"duration\", \"media_type\",\n",
    "    \"operating_hours\", \"is_digital\", \"slot_count\", \"is_available\", \"unit_price\",\n",
    "    \"location_description\", \"image_day\", \"image_night\", \"image_map\",\n",
    "    \"population_target\", \"media_characteristics\", \"case_examples\"\n",
    "]\n",
    "\n",
    "# Step 3: Prepare embedding model using HuggingFace (MiniLM)\n",
    "class BERTSentenceEmbedding:\n",
    "    def __init__(self, model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        return [self._embed(text) for text in texts]\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        return self._embed(text)\n",
    "\n",
    "    def _embed(self, text):\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze(0)\n",
    "        return cls_embedding.cpu().numpy()\n",
    "\n",
    "embedding_function = BERTSentenceEmbedding()\n",
    "\n",
    "# Step 4: Construct documents for Chroma\n",
    "def build_text(row):\n",
    "    return f\"\"\"\n",
    "    위치 설명: {row['location_description']}\n",
    "    타겟: {row['population_target']}\n",
    "    매체 특징: {row['media_characteristics']}\n",
    "    집행 사례: {row['case_examples']}\n",
    "    \"\"\"\n",
    "\n",
    "docs = []\n",
    "for i, row in df.iterrows():\n",
    "    doc = Document(\n",
    "        page_content=build_text(row),\n",
    "        metadata={\n",
    "            \"media_id\": str(row[\"media_id\"]),\n",
    "            \"media_name\": row[\"media_name\"],\n",
    "            \"location\": row[\"location\"],\n",
    "            \"media_type\": row[\"media_type\"],\n",
    "            \"population_target\": row[\"population_target\"],\n",
    "            \"media_characteristics\": row[\"media_characteristics\"],\n",
    "            \"case_examples\": row[\"case_examples\"]\n",
    "        }\n",
    "    )\n",
    "    docs.append(doc)\n",
    "\n",
    "# Step 5: Store in Chroma\n",
    "chroma_collection = Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embedding_function,\n",
    "    collection_name=\"media\",\n",
    "    persist_directory=\"./chroma_media\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3803a4f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x8/x9mhzs_j0yx8btgk3t9m0vvc0000gn/T/ipykernel_2183/570867232.py:1: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  chroma_collection.persist()\n"
     ]
    }
   ],
   "source": [
    "chroma_collection.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "23744721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장된 문서 수: 51\n"
     ]
    }
   ],
   "source": [
    "print(\"저장된 문서 수:\", chroma_collection._collection.count())  # 또는 chroma_collection._collection.count()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395091ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/x8/x9mhzs_j0yx8btgk3t9m0vvc0000gn/T/ipykernel_2183/3638289297.py:19: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  chroma_collection = Chroma(\n"
     ]
    }
   ],
   "source": [
    "# 에이전트: 브랜드 정보를 기반으로 크로마 DB에서 관련 매체 추천\n",
    "\n",
    "from typing import TypedDict\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Step 1: 입력/출력 구조 정의\n",
    "class MatchingInput(TypedDict):\n",
    "    brand_name: str\n",
    "    recent_issue: str\n",
    "    brand_description: str\n",
    "\n",
    "class MatchingOutput(TypedDict):\n",
    "    brand: dict\n",
    "    recommended_package: dict\n",
    "    sales_talking_points: list[str]\n",
    "\n",
    "# Step 2: 임베딩 및 Chroma 연결\n",
    "embedding_function = BERTSentenceEmbedding()\n",
    "chroma_collection = Chroma(\n",
    "    collection_name=\"media\",\n",
    "    embedding_function=embedding_function,\n",
    "    persist_directory=\"./chroma_media\"\n",
    ")\n",
    "\n",
    "# Step 3: LLM 초기화\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Step 4: 에이전트 정의\n",
    "def media_matcher_agent(state: MatchingInput) -> MatchingOutput:\n",
    "    # 1. 쿼리 텍스트 구성\n",
    "    query_text = f\"{state['recent_issue']} / {state['brand_description']}\"\n",
    "\n",
    "    # 2. 유사도 기반 검색\n",
    "    results = chroma_collection.similarity_search_with_score(query_text, k=5)\n",
    "\n",
    "    # 3. 결과 정리 (상위 3개)\n",
    "    top_matches = []\n",
    "    for doc, score in results[:3]:\n",
    "        meta = doc.metadata\n",
    "        top_matches.append({\n",
    "            \"media_id\": meta[\"media_id\"],\n",
    "            \"media_name\": meta[\"media_name\"],\n",
    "            \"location\": meta[\"location\"],\n",
    "            \"media_type\": meta[\"media_type\"],\n",
    "            \"match_score\": int((1 - score) * 100),\n",
    "            \"individual_reason\": f\"{state['recent_issue'].split()[2]} 지역과 유사한 위치 + 타겟 적합성\"\n",
    "        })\n",
    "\n",
    "    # 4. 매칭 사유 요약\n",
    "    matching_reason = f\"{state['brand_name']}의 최근 마케팅 이슈와 지역/타겟 오디언스를 기준으로 선정된 매체 조합입니다.\"\n",
    "\n",
    "    # 5. 세일즈 포인트 생성\n",
    "    prompt = f\"\"\"\n",
    "    브랜드: {state['brand_name']}\n",
    "    이슈: {state['recent_issue']}\n",
    "    매체: {', '.join([m['media_name'] for m in top_matches])}\n",
    "\n",
    "    위 정보를 바탕으로 광고주에게 제안할 세일즈 포인트 3가지를 만들어줘.\n",
    "    \"\"\"\n",
    "    sales_point = llm.invoke(prompt).content.strip().split(\"\\n\")\n",
    "\n",
    "    # 6. 최종 출력 구조 반환\n",
    "    return {\n",
    "        \"brand\": {\n",
    "            \"name\": state[\"brand_name\"],\n",
    "            \"recent_issue\": state[\"recent_issue\"],\n",
    "            \"target_audience\": \"타겟 오디언스 자동 추출 예정\"\n",
    "        },\n",
    "        \"recommended_package\": {\n",
    "            \"package_name\": f\"{state['recent_issue'].split()[2]} 프리미엄 패키지\",\n",
    "            \"media_list\": top_matches,\n",
    "            \"matching_reason\": matching_reason\n",
    "        },\n",
    "        \"sales_talking_points\": [line.strip(\"- \").strip() for line in sales_point if line.strip()]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "539c1b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'brand': {'name': '더바넷', 'recent_issue': '2025년 3월 9일: 서울 잠실 롯데월드몰에 국내 첫 팝업스토어 오픈', 'target_audience': '타겟 오디언스 자동 추출 예정'}, 'recommended_package': {'package_name': '9일: 프리미엄 패키지', 'media_list': [{'media_id': '17', 'media_name': '가로변 버스쉘터 강남대로', 'location': '서울시 강남구 강남대로 일대', 'media_type': '버스정류장 쉘터 광고', 'match_score': -386, 'individual_reason': '9일: 지역과 유사한 위치 + 타겟 적합성'}, {'media_id': '12', 'media_name': '홍대입구역 스칼렛 전광판', 'location': '서울시 마포구 양화로 148', 'media_type': '벽면형 세로 사이니지', 'match_score': -390, 'individual_reason': '9일: 지역과 유사한 위치 + 타겟 적합성'}, {'media_id': '2', 'media_name': '서울 고속버스터미널 (경부선)', 'location': '서울시 서초구 신반포로 194', 'media_type': '옥상형 가로 사이니지', 'match_score': -392, 'individual_reason': '9일: 지역과 유사한 위치 + 타겟 적합성'}], 'matching_reason': '더바넷의 최근 마케팅 이슈와 지역/타겟 오디언스를 기준으로 선정된 매체 조합입니다.'}, 'sales_talking_points': ['다음은 더바넷의 팝업스토어 오픈을 홍보하기 위한 세일즈 포인트 3가지입니다:', '1. **최초의 팝업스토어 경험 제공**:', '더바넷은 2025년 3월 9일 서울 잠실 롯데월드몰에 국내 최초의 팝업스토어를 오픈합니다. 소비자들에게 특별한 경험과 함께 한정판 제품을 체험할 수 있는 기회를 제공하여 브랜드 이미지와 충성도를 강화할 수 있습니다. 팝업스토어를 통해 소비자와의 직접적인 소통을 통해 더바넷의 브랜드 가치를 극대화할 수 있습니다.', '2. **전략적 위치를 활용한 높은 노출도**:', '강남대로의 가로변 버스쉘터, 홍대입구역의 스칼렛 전광판, 서울 고속버스터미널 등 유동인구가 많은 주요 장소에서 광고를 진행함으로써 브랜드의 가시성을 극대화할 수 있습니다. 이러한 위치 선택은 대중교통 이용자와 젊은 소비층을 효과적으로 타겟팅함으로써 브랜드 인식을 높이고 소비자의 관심을 끌 수 있습니다.', '3. **한정된 시간 동안의 특별 프로모션**:', '팝업스토어 오픈을 기념하여 고객들에게 특별 할인, 사은품 증정, 그리고 한정판 제품 판매 등의 프로모션을 진행할 수 있습니다. 이러한 전략은 소비자들의 구매욕구를 자극하고, 더바넷을 방문하도록 유도하여 와서 직접 체험하도록 만들 수 있는 기회를 제공합니다. 이와 함께 소셜 미디어와의 연계를 통해 2차 홍보 효과를 기대할 수 있습니다.', '이러한 세일즈 포인트를 통해 더바넷의 팝업스토어 성공적인 출발을 도와줄 수 있습니다.']}\n"
     ]
    }
   ],
   "source": [
    "response = media_matcher_agent({\n",
    "    \"brand_name\": \"더바넷\",\n",
    "    \"recent_issue\": \"2025년 3월 9일: 서울 잠실 롯데월드몰에 국내 첫 팝업스토어 오픈\",\n",
    "    \"brand_description\": \"2021년 론칭한 캐주얼 브랜드로, 20·30세대 고객에게 가장 트렌디한 브랜드로 손꼽히며, 가방과 모자, 액세서리를 포함한 다양한 상품을 선보인다.\"\n",
    "})\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b5b53a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OoHMarketingSalse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
