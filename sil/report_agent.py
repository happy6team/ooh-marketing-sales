from typing import TypedDict, Optional
from langchain_core.prompts import ChatPromptTemplate
from langgraph.graph import StateGraph
from langchain_openai import ChatOpenAI
from dotenv import load_dotenv
import mysql.connector
from langchain_community.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from docx import Document
import pandas as pd
import os
from docx.shared import Inches
from transformers import AutoTokenizer, AutoModel
import torch
import json
from decimal import Decimal


# --- ğŸ” ìƒíƒœ ì •ì˜ ---
class ProposalState(TypedDict, total=False):
    brand_name: Optional[str]
    brand_info: Optional[str]
    client_needs: Optional[str]
    recent_issues: Optional[str]
    sales_status: Optional[str]
    recommended_media: Optional[str]
    previous_campaigns: Optional[str]
    proposal_text: Optional[str]
    proposal_file_path: Optional[str]
    media_info: list

AgentState = ProposalState

# --- .env ì—ì„œ OPENAI API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸° ---
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

llm = ChatOpenAI(model="gpt-4o", openai_api_key=openai_api_key)

# --- HuggingFace ê¸°ë°˜ ì„ë² ë”© í´ë˜ìŠ¤ ---
class BERTSentenceEmbedding:
    def __init__(self, model_name="sentence-transformers/all-MiniLM-L6-v2"):
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModel.from_pretrained(model_name)

    def embed_documents(self, texts):
        return [self._embed(text) for text in texts]

    def embed_query(self, text):
        return self._embed(text)

    def _embed(self, text):
        inputs = self.tokenizer(text, return_tensors="pt", truncation=True, padding=True)
        with torch.no_grad():
            outputs = self.model(**inputs)
        cls_embedding = outputs.last_hidden_state[:, 0, :]  # (batch_size, hidden_size)
        return cls_embedding.squeeze(0).cpu().numpy()

# --- embedding_function ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ---
embedding_function = BERTSentenceEmbedding()

# --- ğŸ—„ï¸ Tool êµ¬ì„± (ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œ Stub í˜•íƒœë¡œ Tool ì„¤ì •) ---
# ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œëŠ” ì•„ë˜ Toolë“¤ì„ LangChain Toolkitìœ¼ë¡œ êµ¬í˜„

def db_query_tool(query: str):
    import mysql.connector
    from dotenv import load_dotenv
    import os

    load_dotenv()  # .env íŒŒì¼ ë¡œë“œ

    host = os.getenv("DB_HOST")
    user = os.getenv("DB_USER")
    password = os.getenv("DB_PASSWORD")
    database = os.getenv("DB_NAME")

    conn = mysql.connector.connect(
        host=host,
        user=user,
        password=password,
        database=database
    )
    cursor = conn.cursor(dictionary=True)
    cursor.execute(query)
    results = cursor.fetchall()
    cursor.close()
    conn.close()
    return results


def web_search_tool(query: str) -> str:
    return f"[WEB SEARCH RESULT for: {query}]"

def vectordb_search_tool(query: str, collection_name: str, top_k: int = 3) -> str:
    vectorstore = Chroma(
        collection_name=collection_name,
        embedding_function=embedding_function
    )
    results = vectorstore.similarity_search(query, k=top_k)

    combined_results = []
    for doc in results:
        content = doc.page_content

        content_lines = [f"- {line.strip()}" for line in content.split(",")]
        content_formatted = "\n".join(content_lines)

        image_url = doc.metadata.get("execution_image_url", "")
        if image_url.startswith("/images/"):
            image_url = "../" + image_url.lstrip("/")
        elif image_url == "":
            image_url = "[ì´ë¯¸ì§€ ì—†ìŒ]"

        content_with_image = f"{content_formatted}\n[ì´ë¯¸ì§€ ë³´ê¸°]({image_url})"
        combined_results.append(content_with_image)

    return "\n\n---\n\n".join(combined_results)

# --- ChromaDBì— campaign_media ë°ì´í„° ì˜¬ë¦¬ê¸° (ìµœì´ˆ 1íšŒ) ---
csv_path = "../data/data_sample/campaign_media.csv"
df = pd.read_csv(csv_path)

def row_to_text(row):
    return (
        f"ìº í˜ì¸ ID: {row['campaign_id']}, "
        f"ë§¤ì²´ ID: {row['media_id']}, "
        f"ì‹œì‘ì¼: {row['start_date']}, "
        f"ì¢…ë£Œì¼: {row['end_date']}, "
        f"êµ¬ì¢Œ ìˆ˜: {row['slot_count']}, "
        f"ì§‘í–‰ ê°€ê²©: {row['executed_price']}, "
        f"ì§„í–‰ ìƒíƒœ: {row['campaign_media_status']}"
    )

texts = []
metadatas = []

for idx, row in df.iterrows():
    texts.append(row_to_text(row))
    metadatas.append({"execution_image_url": row["execution_image_url"]})

# --- ë¬¸ì„œ ë¶„í•  ---
splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
docs = splitter.create_documents(texts, metadatas=metadatas)

# --- Chroma ì»¬ë ‰ì…˜ì— ì €ì¥ (HuggingFace ì„ë² ë”© ì‚¬ìš©) ---
vectorstore = Chroma.from_documents(
    documents=docs,
    embedding=embedding_function,  # âœ… embedding_functionìœ¼ë¡œ ìˆ˜ì •
    collection_name="campaign_media_chroma_hf"  # âœ… ìƒˆ ì»¬ë ‰ì…˜ ì´ë¦„
)

print(f"âœ… HuggingFace ì„ë² ë”©ìœ¼ë¡œ {len(docs)}ê°œ ë¬¸ì„œ ì €ì¥ ì™„ë£Œ!")

def query_brand_and_sales_logs(brand_name: str):
    load_dotenv()
    conn = mysql.connector.connect(
        host=os.getenv("DB_HOST"),
        user=os.getenv("DB_USER"),
        password=os.getenv("DB_PASSWORD"),
        database=os.getenv("DB_NAME")
    )
    cursor = conn.cursor(dictionary=True)

    # 1ï¸âƒ£ ë¸Œëœë“œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
    cursor.execute("""
        SELECT * FROM brand WHERE brand_name = %s
    """, (brand_name,))
    brand_info = cursor.fetchone()

    if not brand_info:
        cursor.close()
        conn.close()
        return None, None

    brand_id = brand_info["brand_id"]

    # 2ï¸âƒ£ ìµœì‹  sales_log ì •ë³´ ê°€ì ¸ì˜¤ê¸° (brand_id ê¸°ì¤€)
    cursor.execute("""
        SELECT * FROM sales_log 
        WHERE brand_id = %s 
        ORDER BY contact_time DESC 
        LIMIT 1
    """, (brand_id,))
    latest_sales_log = cursor.fetchone()

    cursor.close()
    conn.close()

    return brand_info, latest_sales_log

def decimal_default(obj):
    if isinstance(obj, Decimal):
        return float(obj)
    raise TypeError

# --- Node 1: ë¸Œëœë“œ ì •ë³´ + ê³ ê° ìš”êµ¬ì‚¬í•­ ë¶„ì„ ---
def analyze_brand_and_needs(state: ProposalState):
    brand_name = state["brand_name"]

    brand_info, latest_sales_log = query_brand_and_sales_logs(brand_name)

    if not brand_info:
        raise ValueError(f"ë¸Œëœë“œ '{brand_name}' ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # ìµœì‹  ê³ ê° ìš”êµ¬ì‚¬í•­ ìš”ì•½ ê°€ì ¸ì˜¤ê¸°
    client_needs = latest_sales_log["client_needs_summary"] if latest_sales_log else "ìµœê·¼ ê³ ê° ìš”êµ¬ì‚¬í•­ ì •ë³´ ì—†ìŒ"

    # ë¸Œëœë“œ ì´ìŠˆ ë° ìƒíƒœ ì •ë³´ ì¶”ê°€ (LLM í”„ë¡¬í”„íŠ¸ì— ë„ì›€ë¨)
    recent_issues = brand_info.get("recent_brand_issues") or "ë¸Œëœë“œ ì´ìŠˆ ì •ë³´ ì—†ìŒ"
    sales_status = brand_info.get("sales_status") or "ìƒíƒœ ì •ë³´ ì—†ìŒ"

    return {
        **state,
        "brand_info": brand_info,
        "client_needs": client_needs,
        "recent_issues": recent_issues,
        "sales_status": sales_status
    }

# --- Node 2: ìœ ì‚¬ ì§‘í–‰ ì‚¬ë¡€ ì¡°íšŒ ì‚¬ì§„ ì •ë³´ ë¨¼ì €---
def retrieve_previous_campaigns(state: ProposalState):
    client_needs = state.get("client_needs") or "ì˜¥ì™¸ ê´‘ê³  ì§‘í–‰ ì‚¬ë¡€"

    collection_name = "campaign_media_chroma_hf"  # ë²¡í„°ìŠ¤í† ì–´ ì»¬ë ‰ì…˜ ì´ë¦„
    similar_cases = vectordb_search_tool(client_needs, collection_name)

    return {**state, "previous_campaigns": similar_cases}

# --- Node 3: ë§¤ì²´ ì¶”ì²œ ë° ë§¤ì¹­ ìœ ì‚¬ ì§‘í–‰ ì‚¬ë¡€ì™€ ê¸°ì¡´ ë§¤ì²´ í†µí•©í•´ì„œ MZ íŒ¨í‚¤ì§€ ë§¤ì²´ ì—¬ëŸ¬ê°œ ---
# media, ì›¹ê²€ìƒ‰?!
def recommend_media(state: ProposalState):
    client_needs = state.get("client_needs") or ""
    db_results = db_query_tool("SELECT * FROM media WHERE quantity > 0;")

    if not db_results or len(db_results) == 0:
        raise ValueError("ì‚¬ìš© ê°€ëŠ¥í•œ ë§¤ì²´ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

    media_info = db_results  # ì´ê±¸ stateì— ë„˜ê¹€

    media_json = json.dumps(db_results, ensure_ascii=False, default=lambda o: float(o) if isinstance(o, Decimal) else str(o))

    prompt = f"""
        ë‹¹ì‹ ì€ ì˜¥ì™¸ ê´‘ê³  ì „ë¬¸ ëŒ€í–‰ì‚¬ì˜ ì „ëµ ê¸°íšìì…ë‹ˆë‹¤.

        ë‹¤ìŒ ë¸Œëœë“œì˜ ê³ ê° ìš”êµ¬ì‚¬í•­ê³¼ ìœ ì‚¬ ì§‘í–‰ ì‚¬ë¡€ë¥¼ ê³ ë ¤í•˜ì—¬ ê°€ì¥ ì í•©í•œ ì˜¥ì™¸ ê´‘ê³  ë§¤ì²´ 3ê°€ì§€ë¥¼ ì¶”ì²œí•´ì•¼ í•©ë‹ˆë‹¤.

        - ë¸Œëœë“œ ê³ ê° ìš”êµ¬ì‚¬í•­: {state.get('client_needs')}
        - ìœ ì‚¬ ì§‘í–‰ ì‚¬ë¡€ ìš”ì•½: {state.get('previous_campaigns')}

        ë‹¤ìŒì€ ì‚¬ìš© ê°€ëŠ¥í•œ ë§¤ì²´ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤:
        {media_json}

        ê°ê° ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ ì¶”ì²œí•˜ì‹­ì‹œì˜¤:
        1. ëŒ€í–‰ì‚¬ ì…ì¥ì—ì„œ ê°€ì¥ ì „ëµì ìœ¼ë¡œ ì¶”ì²œí•˜ëŠ” ë§¤ì²´ (íš¨ê³¼ì™€ ì¸ì§€ë„ê°€ ë†’ìŒ)
        2. ê°€ê²©ì ìœ¼ë¡œ ì €ë ´í•˜ë©´ì„œ íš¨ê³¼ì ì¸ ë§¤ì²´
        3. ê¸°íƒ€ ì¶”ì²œí•  ë§Œí•œ ë§¤ì²´ í•œ ê°€ì§€

        ê° í›„ë³´ ë§¤ì²´ì— ëŒ€í•´ ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•˜ì‹­ì‹œì˜¤:
        - ë§¤ì²´ëª…: {{ë§¤ì²´ëª…}}
        - ì˜ˆìƒ ì§‘í–‰ ê°€ê²©: {{ê¸ˆì•¡}} ì›
        - ì˜ˆìƒ ì§‘í–‰ ê¸°ê°„: {{ê¸°ê°„}}
        - ì˜ˆìƒ ë…¸ì¶œ ë¹ˆë„: {{ë…¸ì¶œ ë¹ˆë„}}
        - ì¶”ì²œ ì´ìœ : {{ì´ìœ }}

        **ë§¤ì²´ëª…: ì´ë¼ëŠ” í‚¤ì›Œë“œë¥¼ ê¼­ í¬í•¨í•˜ê³  ê° ë§¤ì²´ëŠ” ì¤„ë°”ê¿ˆí•˜ì—¬ êµ¬ë¶„í•˜ì„¸ìš”.**
        """

    recommendation = llm.invoke(prompt)
    recommendation_text = recommendation.content  # ë¬¸ìì—´ë¡œ ë³€í™˜
    
    return {
        **state,
        "recommended_media": recommendation_text,
        "media_info": media_info
    }

# --- Node 4: ì œì•ˆì„œ ìƒì„± (Word íŒŒì¼ í¬í•¨) ---
def generate_proposal(state: ProposalState):
    import datetime
    import re
    from docx import Document
    from docx.shared import Inches
    from langchain.prompts import ChatPromptTemplate

    doc = Document()
    doc.add_heading(f"{state['brand_name']} ì˜¥ì™¸ ê´‘ê³  ì œì•ˆì„œ", level=1)
    doc.add_paragraph("") 

    # --- 1. ê³ ê°ì‚¬ ì •ë³´ ---
    doc.add_heading("1. ê³ ê°ì‚¬ ì •ë³´", level=2)
    brand_info = state["brand_info"]

    # brand_infoê°€ dict í˜•íƒœë¼ë©´:
    if isinstance(brand_info, dict):
        for key, value in brand_info.items():
            doc.add_paragraph(f"- {key}: {value}")
    else:
        # CSVì²˜ëŸ¼ í•œ ì¤„ë¡œ ë“¤ì–´ì™”ì„ ê²½ìš° â†’ í‚¤:ê°’ í˜•íƒœë¡œ ì¤„ë°”ê¿ˆ
        lines = re.split(r",|\t", brand_info)
        for line in lines:
            if ':' in line:
                doc.add_paragraph(f"- {line.strip()}")
            elif line.strip():
                doc.add_paragraph(f"- {line.strip()}")

    # --- 2. ìº í˜ì¸ ëª©í‘œ ---
    doc.add_paragraph("") 
    doc.add_heading("2. ìº í˜ì¸ ëª©í‘œ", level=2)
    client_needs = state["client_needs"]

    # ì‰¼í‘œë¡œ êµ¬ë¶„ â†’ ë¬¸ì¥ë³„ë¡œ ì¶œë ¥
    for item in re.split(r",|Â·|â€¢", client_needs):
        if item.strip():
            doc.add_paragraph(f"- {item.strip()}")

    # --- 3. ìœ ì‚¬ ì§‘í–‰ ì‚¬ë¡€ ---
    doc.add_heading("3. ìœ ì‚¬ ì§‘í–‰ ì‚¬ë¡€", level=2)
    previous_campaigns = state["previous_campaigns"]

    cases = previous_campaigns.split("\n\n---\n\n")
    filtered_cases = []
    for idx, case in enumerate(cases, start=1):
        if "ì‚¬ë¡€ 3" in case:
            continue  # ì‚¬ë¡€ 3 ì œì™¸

        # ì´ë¯¸ì§€ URL ì¶”ì¶œ
        image_url = None
        image_match = re.search(r"\[ì´ë¯¸ì§€ ë³´ê¸°\]\((.*?)\)", case)
        if image_match:
            image_url = image_match.group(1).strip()

        # í…ìŠ¤íŠ¸ì—ì„œ [ì´ë¯¸ì§€ ë³´ê¸°] ë¶€ë¶„ ì‚­ì œ
        case_text = re.sub(r"\[ì´ë¯¸ì§€ ë³´ê¸°\]\(.*?\)", "", case).strip()
        filtered_cases.append((f"- ì‚¬ë¡€ {idx}\n{case_text}", image_url))

    # âœ… 3í–‰ 2ì—´ì§œë¦¬ í‘œ ìƒì„± (í–‰ = ì‚¬ë¡€ ê°œìˆ˜, ì—´ = 2)
    table = doc.add_table(rows=len(filtered_cases), cols=2)
    table.style = 'Table Grid'

    for row_idx, (case_text, image_url) in enumerate(filtered_cases):
        # ì™¼ìª½ ì…€: ì‚¬ë¡€ ë‚´ìš©
        table.cell(row_idx, 0).text = case_text

        # ì˜¤ë¥¸ìª½ ì…€: ì´ë¯¸ì§€ ë˜ëŠ” í…ìŠ¤íŠ¸
        cell_image = table.cell(row_idx, 1)
        if image_url and image_url.endswith((".jpg", ".png")):
            try:
                run = cell_image.paragraphs[0].add_run()
                run.add_picture(image_url, width=Inches(2.5))
            except Exception as e:
                cell_image.text = f"ì´ë¯¸ì§€ ì‚½ì… ì‹¤íŒ¨ ({e})"
        else:
            cell_image.text = "ì´ë¯¸ì§€ ì—†ìŒ"

    # --- 4. ì¶”ì²œë§¤ì²´ ë° ì§‘í–‰ê³„íš ---
    doc.add_paragraph("") 
    doc.add_heading("4. ì¶”ì²œë§¤ì²´ ë° ì§‘í–‰ê³„íš", level=2)

    recommended_media = state["recommended_media"]
    if hasattr(recommended_media, "content"):
        recommended_media_text = recommended_media.content
    else:
        recommended_media_text = recommended_media

    media_rows = state.get("media_info", [])
    media_image_map = {row["media_name"].strip().lower(): row["image_day_url"] for row in media_rows}

    media_blocks = []
    current_block = ""
    for line in recommended_media_text.split("\n"):
        # â­ ì œëª©ì˜ "**" ì œê±° (block ì¶”ê°€ ì „ ì²˜ë¦¬)
        clean_line = re.sub(r"\*+", "", line.strip())
        if re.match(r"^\d+\.", clean_line):
            if current_block:
                media_blocks.append(current_block.strip())
            current_block = clean_line
        elif clean_line:
            current_block += "\n" + clean_line
    if current_block:
        media_blocks.append(current_block.strip())

    table = doc.add_table(rows=len(media_blocks), cols=2)
    table.style = 'Table Grid'

    for idx, block in enumerate(media_blocks):
        # ë§¤ì²´ëª… ì¶”ì¶œ
        name_match = re.search(r"ë§¤ì²´ëª…\s*[:ï¼š]\s*(.+)", block)
        if name_match:
            media_name = name_match.group(1).strip()
        else:
            name_match = re.search(r"^\d+\.\s*(.+)", block)
            media_name = name_match.group(1).strip() if name_match else "ì¶”ì²œ ë§¤ì²´"

        media_name_clean = media_name.replace("*", "").strip().lower()
        image_url = media_image_map.get(media_name_clean)
        if image_url and image_url.startswith("/images/"):
            image_url = "../images/" + image_url[len("/images/"):]
        # ì™¼ìª½: ì„¤ëª…
        table.cell(idx, 0).text = block
        # ì˜¤ë¥¸ìª½: ì´ë¯¸ì§€
        cell_image = table.cell(idx, 1)
        if image_url and image_url.endswith((".jpg", ".png")):
            try:
                run = cell_image.paragraphs[0].add_run()
                run.add_picture(image_url, width=Inches(3))
            except Exception as e:
                cell_image.text = f"ì´ë¯¸ì§€ ì‚½ì… ì‹¤íŒ¨ ({e})"
        else:
            cell_image.text = "ì´ë¯¸ì§€ ì—†ìŒ"

    # --- 5. ê²°ë¡  (LLM ì‚¬ìš©) ---
    doc.add_paragraph("") 
    doc.add_heading("5. ê²°ë¡ ", level=2)

    # LLM í”„ë¡¬í”„íŠ¸
    prompt = ChatPromptTemplate.from_template("""
    ë¸Œëœë“œëª…: {brand_name}
    ìº í˜ì¸ ëª©í‘œ: {client_needs}
    ì¶”ì²œ ë§¤ì²´: {recommended_media}

    ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìº í˜ì¸ì˜ ê²°ë¡  ë¶€ë¶„ì„ ì‘ì„±í•˜ì„¸ìš”.
    """)
    chain = prompt | llm
    conclusion = chain.invoke(state).content

    doc.add_paragraph(conclusion)

    now = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    file_name = f"{state['brand_name']}_ì œì•ˆì„œ_{now}.docx"
    doc.save(file_name)

    return {**state, "proposal_text": conclusion, "proposal_file_path": file_name}

# --- ğŸ”— ê·¸ë˜í”„ êµ¬ì„± ---
graph = StateGraph(ProposalState)

graph.add_node("AnalyzeBrandAndNeeds", analyze_brand_and_needs)
graph.add_node("RecommendMedia", recommend_media)
graph.add_node("RetrievePreviousCampaigns", retrieve_previous_campaigns)
graph.add_node("GenerateProposal", generate_proposal)

graph.set_entry_point("AnalyzeBrandAndNeeds")
graph.add_edge("AnalyzeBrandAndNeeds", "RetrievePreviousCampaigns")
graph.add_edge("RetrievePreviousCampaigns", "RecommendMedia")
graph.add_edge("RecommendMedia", "GenerateProposal")
graph.set_finish_point("GenerateProposal")

proposal_graph = graph.compile()

# --- ğŸš€ ì‹¤í–‰ ì˜ˆì‹œ ---
initial_state = {
    "brand_name": "ìœ ë‹ˆí´ë¡œì½”ë¦¬ì•„",
}

final_state = proposal_graph.invoke(initial_state)

print("âœ… ìµœì¢… ì œì•ˆì„œ:\n")
print(final_state["proposal_text"])
print(f"ğŸ“„ ì œì•ˆì„œ Word íŒŒì¼ ê²½ë¡œ: {final_state['proposal_file_path']}")