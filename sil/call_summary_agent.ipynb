{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸:\n",
      " ì•ˆë…•í•˜ì„¸ìš” ì˜¤ê°œê´‘ê³ ëŒ€ í–‰ì‚¬ ì˜¬ë¦¬ì§ˆ êµ¿ì…ë‹ˆë‹¤. í˜¹ì‹œ ì–¸ì–´ë¶€ ë‹´ë‹¹ì ë§ìœ¼ì‹ ê°€ìš”? ë„¤ ë§ìŠµë‹ˆë‹¤.  ë„¤ ì•ˆë…•í•˜ì„¸ìš”. ë‹¤ë¦„ì´ ì•„ë‹ˆë¼ ì´ë²ˆ ì‹ ì œí’ˆ ì¶œì‹œì— ë§ì¶°ì„œ ì €í¬ê°€ í™ëŒ€ ì§€í•˜ì²  ë§¤ì²´ë¥¼ ì œí•œë“œë¦¬ê³ ì í•˜ëŠ”ë° í˜¹ì‹œ ê´€ì‹¬ ìˆìœ¼ì‹¤ê¹Œìš”? í™ëŒ€ê°€ ì–¸ì–´ë¶€ ì£¼ìš” íƒ€ê³„ì¸µì¸ mgì„¸ëŒ€ì™€ ë”± ë§ì„ ê²ƒ ê°™ì•„ì„œìš”.  ì•„ ì €í¬ê°€ ì´ë²ˆì— í™ëŒ€ëŠ” ë§ê³  ì„±ìˆ˜ì˜ íŒŒë²„ìŠ¤í† ë¦¬ ê³„íšì¸ë° í˜¹ì‹œ ì„±ìˆ™ ì¢€ ë§¤ì²´ë„ ìˆë‚˜ìš”? ë„¤ ë¬¼ë¡ ì´ì£ . ì„±ìˆ˜ì—­ ê·¼ì²˜ ë¿ë§Œ ì•„ë‹ˆë¼ ì„±ìˆ˜ ì¹´í˜ ê±°ë¦¬ ì¤‘ì‹¬ìœ¼ë¡œ ì €í¬ê°€ ì—¬ëŸ¬ ë§¤ì²´ë¥¼ ë³´ìœ í•˜ê³  ìˆëŠ”ë° í˜¹ì‹œ ì œê°€ ë¯¸íŒ…ìœ¼ë¡œ ìì„¸í•˜ê²Œ ì„¤ëª…ë“œë ¤ë„ ë ê¹Œìš”? ì£„ì†¡í•œë° ì œê°€ ë¯¸íŒ… ì–´ë¦´ ê²ƒ ê°™ê³ ìš”. ì´ë©œë¡œ ì¼ë‹¨ ì œí•œì„œ ë³´ë‚´ì£¼ì„¸ìš”. ë„¤ ê·¸ëŸ¼ ì €í¬ í†µí•© ì˜¤ê°œ ê´‘ê³  ì œí•œì„œì™€ í•¨ê»˜ ì„±ìˆ˜ íŒŒë²…ì„ ë§ì¶˜ ì œí•œì„œ ë”°ë¡œ ë³´ë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.  í˜¹ì‹œ ë‹´ë‹´ìë¶„ ì„±í•¨ê³¼ ì´ë©”ì¼ ì•Œ ìˆ˜ ìˆì„ê¹Œìš”? ì œ ì´ë¦„ì€ ì´ íš¨ì •ì´ê³ ìš”. ì´ë©”ì¼ì€ sgsgk113 ê³¨ë±…ì´ ìŠ¤í¬ë¼ë‹¤ì»´ì…ë‹ˆë‹¤. ë„¤ sgsgk113 ê³¨ë±…ì´ skal8.coì— ë§ìœ¼ì‹œì£ ? ì˜¤ëŠ˜ ì¤‘ìœ¼ë¡œ ë§¤ì¼ ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤. ë„¤ ê°ì‚¬í•©ë‹ˆë‹¤.\n",
      "ğŸ” ìš”ì•½ ë° ìš”êµ¬ì‚¬í•­ ì •ë¦¬:\n",
      "- ë¸Œëœë“œ ë‹´ë‹¹ì ì´ë¦„: ì´íš¨ì •\n",
      "- ì—°ë½ì²˜: sgsgk113@skal8.co\n",
      "- ì§€ì—­: ì„±ìˆ˜\n",
      "- ë§¤ì²´: ì„±ìˆ˜ì—­ ê·¼ì²˜ ë° ì„±ìˆ˜ ì¹´í˜ ê±°ë¦¬ ì¤‘ì‹¬\n",
      "- íƒ€ê²Ÿì¸µ: MGì„¸ëŒ€\n",
      "- ë¹„ê³  (ë¯¸íŒ… ë‚ ì§œ, ì¶”í›„ ì—°ë½ ë“±): ë¯¸íŒ… ëŒ€ì‹  ì´ë©”ì¼ë¡œ ì œì•ˆì„œ ìš”ì²­, ì˜¤ëŠ˜ ì¤‘ìœ¼ë¡œ ì´ë©”ì¼ ë°œì†¡ ì˜ˆì •\n",
      "- ì„±ì‚¬ ì—¬ë¶€: ë¯¸ì • (ì œì•ˆì„œ ë°œì†¡ í›„ ê²°ì •ë  ê°€ëŠ¥ì„± ìˆìŒ)\n",
      "âœ… sales_log í…Œì´ë¸”ì— ë°ì´í„° ì €ì¥ ì™„ë£Œ\n",
      "ğŸ—‚ï¸ ìµœì¢… ì €ì¥ëœ í•„ë“œ:\n",
      "{'manager_name': 'ì´íš¨ì •', 'manager_email': 'sgsgk113@skal8.co', 'call_full_text': ' ì•ˆë…•í•˜ì„¸ìš” ì˜¤ê°œê´‘ê³ ëŒ€ í–‰ì‚¬ ì˜¬ë¦¬ì§ˆ êµ¿ì…ë‹ˆë‹¤. í˜¹ì‹œ ì–¸ì–´ë¶€ ë‹´ë‹¹ì ë§ìœ¼ì‹ ê°€ìš”? ë„¤ ë§ìŠµë‹ˆë‹¤.  ë„¤ ì•ˆë…•í•˜ì„¸ìš”. ë‹¤ë¦„ì´ ì•„ë‹ˆë¼ ì´ë²ˆ ì‹ ì œí’ˆ ì¶œì‹œì— ë§ì¶°ì„œ ì €í¬ê°€ í™ëŒ€ ì§€í•˜ì²  ë§¤ì²´ë¥¼ ì œí•œë“œë¦¬ê³ ì í•˜ëŠ”ë° í˜¹ì‹œ ê´€ì‹¬ ìˆìœ¼ì‹¤ê¹Œìš”? í™ëŒ€ê°€ ì–¸ì–´ë¶€ ì£¼ìš” íƒ€ê³„ì¸µì¸ mgì„¸ëŒ€ì™€ ë”± ë§ì„ ê²ƒ ê°™ì•„ì„œìš”.  ì•„ ì €í¬ê°€ ì´ë²ˆì— í™ëŒ€ëŠ” ë§ê³  ì„±ìˆ˜ì˜ íŒŒë²„ìŠ¤í† ë¦¬ ê³„íšì¸ë° í˜¹ì‹œ ì„±ìˆ™ ì¢€ ë§¤ì²´ë„ ìˆë‚˜ìš”? ë„¤ ë¬¼ë¡ ì´ì£ . ì„±ìˆ˜ì—­ ê·¼ì²˜ ë¿ë§Œ ì•„ë‹ˆë¼ ì„±ìˆ˜ ì¹´í˜ ê±°ë¦¬ ì¤‘ì‹¬ìœ¼ë¡œ ì €í¬ê°€ ì—¬ëŸ¬ ë§¤ì²´ë¥¼ ë³´ìœ í•˜ê³  ìˆëŠ”ë° í˜¹ì‹œ ì œê°€ ë¯¸íŒ…ìœ¼ë¡œ ìì„¸í•˜ê²Œ ì„¤ëª…ë“œë ¤ë„ ë ê¹Œìš”? ì£„ì†¡í•œë° ì œê°€ ë¯¸íŒ… ì–´ë¦´ ê²ƒ ê°™ê³ ìš”. ì´ë©œë¡œ ì¼ë‹¨ ì œí•œì„œ ë³´ë‚´ì£¼ì„¸ìš”. ë„¤ ê·¸ëŸ¼ ì €í¬ í†µí•© ì˜¤ê°œ ê´‘ê³  ì œí•œì„œì™€ í•¨ê»˜ ì„±ìˆ˜ íŒŒë²…ì„ ë§ì¶˜ ì œí•œì„œ ë”°ë¡œ ë³´ë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.  í˜¹ì‹œ ë‹´ë‹´ìë¶„ ì„±í•¨ê³¼ ì´ë©”ì¼ ì•Œ ìˆ˜ ìˆì„ê¹Œìš”? ì œ ì´ë¦„ì€ ì´ íš¨ì •ì´ê³ ìš”. ì´ë©”ì¼ì€ sgsgk113 ê³¨ë±…ì´ ìŠ¤í¬ë¼ë‹¤ì»´ì…ë‹ˆë‹¤. ë„¤ sgsgk113 ê³¨ë±…ì´ skal8.coì— ë§ìœ¼ì‹œì£ ? ì˜¤ëŠ˜ ì¤‘ìœ¼ë¡œ ë§¤ì¼ ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤. ë„¤ ê°ì‚¬í•©ë‹ˆë‹¤.', 'call_memo': '- ë¸Œëœë“œ ë‹´ë‹¹ì ì´ë¦„: ì´íš¨ì •\\n- ì—°ë½ì²˜: sgsgk113@skal8.co\\n- ì§€ì—­: ì„±ìˆ˜\\n- ë§¤ì²´: ì„±ìˆ˜ì—­ ê·¼ì²˜ ë° ì„±ìˆ˜ ì¹´í˜ ê±°ë¦¬ ì¤‘ì‹¬\\n- íƒ€ê²Ÿì¸µ: MGì„¸ëŒ€\\n- ë¹„ê³  (ë¯¸íŒ… ë‚ ì§œ, ì¶”í›„ ì—°ë½ ë“±): ë¯¸íŒ… ëŒ€ì‹  ì´ë©”ì¼ë¡œ ì œì•ˆì„œ ìš”ì²­, ì˜¤ëŠ˜ ì¤‘ìœ¼ë¡œ ì´ë©”ì¼ ë°œì†¡ ì˜ˆì •\\n- ì„±ì‚¬ ì—¬ë¶€: ë¯¸ì • (ì œì•ˆì„œ ë°œì†¡ í›„ ê²°ì •ë  ê°€ëŠ¥ì„± ìˆìŒ)', 'client_needs_summary': 'ì§€ì—­: ì„±ìˆ˜\\në§¤ì²´: ì„±ìˆ˜ì—­ ê·¼ì²˜ ë° ì„±ìˆ˜ ì¹´í˜ ê±°ë¦¬ ì¤‘ì‹¬\\níƒ€ê²Ÿì¸µ: MGì„¸ëŒ€'}\n"
     ]
    }
   ],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "from typing import TypedDict, Annotated\n",
    "from langchain_core.messages import BaseMessage\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import re\n",
    "import mysql.connector\n",
    "from datetime import datetime\n",
    "\n",
    "# 1ï¸âƒ£ State ì •ì˜\n",
    "class CallingState(TypedDict):\n",
    "    full_text: Annotated[str, \"Transcribed Text\"]\n",
    "    summary: Annotated[str, \"Summarized Info\"]\n",
    "    messages: Annotated[list[BaseMessage], \"Messages\"]\n",
    "\n",
    "# 2ï¸âƒ£ ë¹ˆê°’ -> None ë³€í™˜ í•¨ìˆ˜\n",
    "def empty_to_none(value):\n",
    "    if value and value.lower() != \"nan\":\n",
    "        return value.strip()\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# 3ï¸âƒ£ ìŒì„± ì¸ì‹ â†’ State ë°˜í™˜\n",
    "def transcribe(state: CallingState) -> CallingState:\n",
    "    model = WhisperModel(\"base\")\n",
    "    segments, info = model.transcribe(\"calling_data.m4a\")\n",
    "    full_text = \" \".join([seg.text for seg in segments])\n",
    "    print(\"ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸:\")\n",
    "    print(full_text)\n",
    "\n",
    "    return CallingState(\n",
    "        full_text=full_text,\n",
    "        summary=\"\",\n",
    "        messages=[]\n",
    "    )\n",
    "\n",
    "# 4ï¸âƒ£ ìš”ì•½ ë° ìš”êµ¬ì‚¬í•­ ì •ë¦¬ â†’ State ê°±ì‹ \n",
    "def summarize(state: CallingState) -> CallingState:\n",
    "    load_dotenv()\n",
    "    client = openai.OpenAI()\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    ë‹¤ìŒ ê³ ê°ê³¼ì˜ í†µí™” ë‚´ìš©ì„ ìš”ì•½í•˜ê³ , ê³ ê°ì˜ ìš”êµ¬ì‚¬í•­ì„ ë‹¤ìŒ í•„ë“œë³„ë¡œ ì •ë¦¬í•´ì¤˜:\n",
    "    - ë¸Œëœë“œ ë‹´ë‹¹ì ì´ë¦„:\n",
    "    - ì—°ë½ì²˜:\n",
    "    - ì§€ì—­:\n",
    "    - ë§¤ì²´:\n",
    "    - íƒ€ê²Ÿì¸µ:\n",
    "    - ë¹„ê³  (ë¯¸íŒ… ë‚ ì§œ, ì¶”í›„ ì—°ë½ ë“±):\n",
    "    - ì„±ì‚¬ ì—¬ë¶€:\n",
    "\n",
    "    í†µí™” ë‚´ìš©:\n",
    "    \\\"\\\"\\\"{state['full_text']}\\\"\\\"\\\"\n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"ë„ˆëŠ” ì˜ì—… ë‹´ë‹¹ìì˜ ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ê³ ê°ì˜ ìš”êµ¬ì‚¬í•­ì„ ì •í™•í•˜ê²Œ ì •ë¦¬í•´ì•¼ í•´.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.2\n",
    "    )\n",
    "\n",
    "    summary = response.choices[0].message.content\n",
    "    print(\"ğŸ” ìš”ì•½ ë° ìš”êµ¬ì‚¬í•­ ì •ë¦¬:\")\n",
    "    print(summary)\n",
    "\n",
    "    return CallingState(\n",
    "        full_text=state[\"full_text\"],\n",
    "        summary=summary,\n",
    "        messages=[]\n",
    "    )\n",
    "\n",
    "# 5ï¸âƒ£ GPT ìš”ì•½ì—ì„œ í•„ë“œë³„ ê°’ ì¶”ì¶œ\n",
    "def extract_fields(summary: str, full_text: str):\n",
    "    def extract(label):\n",
    "        match = re.search(f\"{label}: *(.*)\", summary)\n",
    "        return match.group(1).strip() if match else \"\"\n",
    "\n",
    "    # í•„ë“œë³„ ì¶”ì¶œ\n",
    "    manager_name = extract(\"ë¸Œëœë“œ ë‹´ë‹¹ì ì´ë¦„\")\n",
    "    manager_email = extract(\"ì—°ë½ì²˜\")\n",
    "\n",
    "    region = extract(\"ì§€ì—­\")\n",
    "    media = extract(\"ë§¤ì²´\")\n",
    "    target = extract(\"íƒ€ê²Ÿì¸µ\")\n",
    "\n",
    "    # call_memoëŠ” **ìš”ì•½ ì „ì²´**ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©!\n",
    "    call_memo = summary\n",
    "\n",
    "    # client_needs_summary = ì§€ì—­ + ë§¤ì²´ + íƒ€ê²Ÿì¸µ ì´ì–´ ë¶™ì´ê¸°\n",
    "    summary_parts = []\n",
    "    if region:\n",
    "        summary_parts.append(f\"ì§€ì—­: {region}\")\n",
    "    if media:\n",
    "        summary_parts.append(f\"ë§¤ì²´: {media}\")\n",
    "    if target:\n",
    "        summary_parts.append(f\"íƒ€ê²Ÿì¸µ: {target}\")\n",
    "    client_needs_summary = \"\\n\".join(summary_parts) if summary_parts else None\n",
    "\n",
    "    return {\n",
    "        \"manager_name\": manager_name,\n",
    "        \"manager_email\": manager_email,\n",
    "        \"call_full_text\": full_text,\n",
    "        \"call_memo\": call_memo,  # ìš”ì•½ ì „ì²´ê°€ ë©”ëª¨ë¡œ\n",
    "        \"client_needs_summary\": client_needs_summary\n",
    "    }\n",
    "\n",
    "# 6ï¸âƒ£ MariaDBì— ë°ì´í„° ì €ì¥\n",
    "def save_to_mariadb(fields: dict):\n",
    "    load_dotenv()\n",
    "    conn = mysql.connector.connect(\n",
    "        host=os.getenv(\"DB_HOST\"),\n",
    "        user=os.getenv(\"DB_USER\"),\n",
    "        password=os.getenv(\"DB_PASSWORD\"),\n",
    "        database=os.getenv(\"DB_NAME\")\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    sql = \"\"\"\n",
    "    INSERT INTO sales_log \n",
    "    (manager_name, manager_email, call_full_text, call_memo, client_needs_summary)\n",
    "    VALUES (%s, %s, %s, %s, %s)\n",
    "    \"\"\"\n",
    "    values = (\n",
    "        empty_to_none(fields[\"manager_name\"]),\n",
    "        empty_to_none(fields[\"manager_email\"]),\n",
    "        empty_to_none(fields[\"call_full_text\"]),\n",
    "        empty_to_none(fields[\"call_memo\"]),\n",
    "        empty_to_none(fields[\"client_needs_summary\"])\n",
    "    )\n",
    "    cursor.execute(sql, values)\n",
    "    conn.commit()\n",
    "    print(\"âœ… sales_log í…Œì´ë¸”ì— ë°ì´í„° ì €ì¥ ì™„ë£Œ\")\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "# 7ï¸âƒ£ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
    "state: CallingState = {\"full_text\": \"\", \"summary\": \"\", \"messages\": []}\n",
    "\n",
    "state = transcribe(state)\n",
    "state = summarize(state)\n",
    "fields = extract_fields(state[\"summary\"], state[\"full_text\"])\n",
    "save_to_mariadb(fields)\n",
    "\n",
    "print(\"ğŸ—‚ï¸ ìµœì¢… ì €ì¥ëœ í•„ë“œ:\")\n",
    "print(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\envs\\OoHMarketingSales\\Lib\\site-packages\\transformers\\utils\\generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸:\n",
      " ì•ˆë…•í•˜ì„¸ìš” ì˜¤ê°œê´‘ê³ ëŒ€ í–‰ì‚¬ ì˜¬ë¦¬ì§ˆ êµ¿ì…ë‹ˆë‹¤. í˜¹ì‹œ ì–¸ì–´ë¶€ ë‹´ë‹¹ì ë§ìœ¼ì‹ ê°€ìš”? ë„¤ ë§ìŠµë‹ˆë‹¤.  ë„¤ ì•ˆë…•í•˜ì„¸ìš”. ë‹¤ë¦„ì´ ì•„ë‹ˆë¼ ì´ë²ˆ ì‹ ì œí’ˆ ì¶œì‹œì— ë§ì¶°ì„œ ì €í¬ê°€ í™ëŒ€ ì§€í•˜ì²  ë§¤ì²´ë¥¼ ì œí•œë“œë¦¬ê³ ì í•˜ëŠ”ë° í˜¹ì‹œ ê´€ì‹¬ ìˆìœ¼ì‹¤ê¹Œìš”? í™ëŒ€ê°€ ì–¸ì–´ë¶€ ì£¼ìš” íƒ€ê³„ì¸µì¸ mgì„¸ëŒ€ì™€ ë”± ë§ì„ ê²ƒ ê°™ì•„ì„œìš”.  ì•„ ì €í¬ê°€ ì´ë²ˆì— í™ëŒ€ëŠ” ë§ê³  ì„±ìˆ˜ì˜ íŒŒë²„ìŠ¤í† ë¦¬ ê³„íšì¸ë° í˜¹ì‹œ ì„±ìˆ™ ì¢€ ë§¤ì²´ë„ ìˆë‚˜ìš”? ë„¤ ë¬¼ë¡ ì´ì£ . ì„±ìˆ˜ì—­ ê·¼ì²˜ ë¿ë§Œ ì•„ë‹ˆë¼ ì„±ìˆ˜ ì¹´í˜ ê±°ë¦¬ ì¤‘ì‹¬ìœ¼ë¡œ ì €í¬ê°€ ì—¬ëŸ¬ ë§¤ì²´ë¥¼ ë³´ìœ í•˜ê³  ìˆëŠ”ë° í˜¹ì‹œ ì œê°€ ë¯¸íŒ…ìœ¼ë¡œ ìì„¸í•˜ê²Œ ì„¤ëª…ë“œë ¤ë„ ë ê¹Œìš”? ì£„ì†¡í•œë° ì œê°€ ë¯¸íŒ… ì–´ë¦´ ê²ƒ ê°™ê³ ìš”. ì´ë©œë¡œ ì¼ë‹¨ ì œí•œì„œ ë³´ë‚´ì£¼ì„¸ìš”. ë„¤ ê·¸ëŸ¼ ì €í¬ í†µí•© ì˜¤ê°œ ê´‘ê³  ì œí•œì„œì™€ í•¨ê»˜ ì„±ìˆ˜ íŒŒë²…ì„ ë§ì¶˜ ì œí•œì„œ ë”°ë¡œ ë³´ë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.  í˜¹ì‹œ ë‹´ë‹´ìë¶„ ì„±í•¨ê³¼ ì´ë©”ì¼ ì•Œ ìˆ˜ ìˆì„ê¹Œìš”? ì œ ì´ë¦„ì€ ì´ íš¨ì •ì´ê³ ìš”. ì´ë©”ì¼ì€ sgsgk113 ê³¨ë±…ì´ ìŠ¤í¬ë¼ë‹¤ì»´ì…ë‹ˆë‹¤. ë„¤ sgsgk113 ê³¨ë±…ì´ skal8.coì— ë§ìœ¼ì‹œì£ ? ì˜¤ëŠ˜ ì¤‘ìœ¼ë¡œ ë§¤ì¼ ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤. ë„¤ ê°ì‚¬í•©ë‹ˆë‹¤.\n",
      "ğŸ” ìš”ì•½ ë° ìš”êµ¬ì‚¬í•­ ì •ë¦¬:\n",
      "- ì§€ì—­: ì„±ìˆ˜\n",
      "- ë§¤ì²´: ì„±ìˆ˜ì—­ ê·¼ì²˜ ë° ì„±ìˆ˜ ì¹´í˜ ê±°ë¦¬ ì¤‘ì‹¬ì˜ ë§¤ì²´\n",
      "- íƒ€ê²Ÿì¸µ: MZì„¸ëŒ€\n",
      "- ë¹„ê³  (ë¯¸íŒ… ë‚ ì§œ, ì¶”í›„ ì—°ë½ ë“±): ë¯¸íŒ…ì€ ì–´ë ¤ìš°ë©°, ì´ë©”ì¼ë¡œ ì œì•ˆì„œ ìš”ì²­\n",
      "- ì—°ë½ì²˜: ì´ë©”ì¼ - sgsgk113@skal8.co\n",
      "- ì„±ì‚¬ ì—¬ë¶€: ì œì•ˆì„œ ë°œì†¡ ì˜ˆì •, ì„±ì‚¬ ì—¬ë¶€ ë¯¸ì •\n",
      "ğŸ—‚ï¸ ìµœì¢… State:\n",
      "{'full_text': ' ì•ˆë…•í•˜ì„¸ìš” ì˜¤ê°œê´‘ê³ ëŒ€ í–‰ì‚¬ ì˜¬ë¦¬ì§ˆ êµ¿ì…ë‹ˆë‹¤. í˜¹ì‹œ ì–¸ì–´ë¶€ ë‹´ë‹¹ì ë§ìœ¼ì‹ ê°€ìš”? ë„¤ ë§ìŠµë‹ˆë‹¤.  ë„¤ ì•ˆë…•í•˜ì„¸ìš”. ë‹¤ë¦„ì´ ì•„ë‹ˆë¼ ì´ë²ˆ ì‹ ì œí’ˆ ì¶œì‹œì— ë§ì¶°ì„œ ì €í¬ê°€ í™ëŒ€ ì§€í•˜ì²  ë§¤ì²´ë¥¼ ì œí•œë“œë¦¬ê³ ì í•˜ëŠ”ë° í˜¹ì‹œ ê´€ì‹¬ ìˆìœ¼ì‹¤ê¹Œìš”? í™ëŒ€ê°€ ì–¸ì–´ë¶€ ì£¼ìš” íƒ€ê³„ì¸µì¸ mgì„¸ëŒ€ì™€ ë”± ë§ì„ ê²ƒ ê°™ì•„ì„œìš”.  ì•„ ì €í¬ê°€ ì´ë²ˆì— í™ëŒ€ëŠ” ë§ê³  ì„±ìˆ˜ì˜ íŒŒë²„ìŠ¤í† ë¦¬ ê³„íšì¸ë° í˜¹ì‹œ ì„±ìˆ™ ì¢€ ë§¤ì²´ë„ ìˆë‚˜ìš”? ë„¤ ë¬¼ë¡ ì´ì£ . ì„±ìˆ˜ì—­ ê·¼ì²˜ ë¿ë§Œ ì•„ë‹ˆë¼ ì„±ìˆ˜ ì¹´í˜ ê±°ë¦¬ ì¤‘ì‹¬ìœ¼ë¡œ ì €í¬ê°€ ì—¬ëŸ¬ ë§¤ì²´ë¥¼ ë³´ìœ í•˜ê³  ìˆëŠ”ë° í˜¹ì‹œ ì œê°€ ë¯¸íŒ…ìœ¼ë¡œ ìì„¸í•˜ê²Œ ì„¤ëª…ë“œë ¤ë„ ë ê¹Œìš”? ì£„ì†¡í•œë° ì œê°€ ë¯¸íŒ… ì–´ë¦´ ê²ƒ ê°™ê³ ìš”. ì´ë©œë¡œ ì¼ë‹¨ ì œí•œì„œ ë³´ë‚´ì£¼ì„¸ìš”. ë„¤ ê·¸ëŸ¼ ì €í¬ í†µí•© ì˜¤ê°œ ê´‘ê³  ì œí•œì„œì™€ í•¨ê»˜ ì„±ìˆ˜ íŒŒë²…ì„ ë§ì¶˜ ì œí•œì„œ ë”°ë¡œ ë³´ë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.  í˜¹ì‹œ ë‹´ë‹´ìë¶„ ì„±í•¨ê³¼ ì´ë©”ì¼ ì•Œ ìˆ˜ ìˆì„ê¹Œìš”? ì œ ì´ë¦„ì€ ì´ íš¨ì •ì´ê³ ìš”. ì´ë©”ì¼ì€ sgsgk113 ê³¨ë±…ì´ ìŠ¤í¬ë¼ë‹¤ì»´ì…ë‹ˆë‹¤. ë„¤ sgsgk113 ê³¨ë±…ì´ skal8.coì— ë§ìœ¼ì‹œì£ ? ì˜¤ëŠ˜ ì¤‘ìœ¼ë¡œ ë§¤ì¼ ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤. ë„¤ ê°ì‚¬í•©ë‹ˆë‹¤.', 'summary': '- ì§€ì—­: ì„±ìˆ˜\\n- ë§¤ì²´: ì„±ìˆ˜ì—­ ê·¼ì²˜ ë° ì„±ìˆ˜ ì¹´í˜ ê±°ë¦¬ ì¤‘ì‹¬ì˜ ë§¤ì²´\\n- íƒ€ê²Ÿì¸µ: MZì„¸ëŒ€\\n- ë¹„ê³  (ë¯¸íŒ… ë‚ ì§œ, ì¶”í›„ ì—°ë½ ë“±): ë¯¸íŒ…ì€ ì–´ë ¤ìš°ë©°, ì´ë©”ì¼ë¡œ ì œì•ˆì„œ ìš”ì²­\\n- ì—°ë½ì²˜: ì´ë©”ì¼ - sgsgk113@skal8.co\\n- ì„±ì‚¬ ì—¬ë¶€: ì œì•ˆì„œ ë°œì†¡ ì˜ˆì •, ì„±ì‚¬ ì—¬ë¶€ ë¯¸ì •', 'messages': []}\n"
     ]
    }
   ],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "from typing import TypedDict, Annotated\n",
    "from langchain_core.messages import BaseMessage\n",
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 1ï¸âƒ£ State ì •ì˜\n",
    "class CallingState(TypedDict):\n",
    "    full_text: Annotated[str, \"Transcribed Text\"]\n",
    "    summary: Annotated[str, \"Summarized Info\"]\n",
    "    messages: Annotated[list[BaseMessage], \"Messages\"]  # í–¥í›„ í™•ì¥ìš©\n",
    "\n",
    "# 2ï¸âƒ£ ìŒì„± ì¸ì‹ í•¨ìˆ˜ â†’ State ë°˜í™˜\n",
    "def transcribe(state: CallingState) -> CallingState:\n",
    "    model = WhisperModel(\"base\")\n",
    "    segments, info = model.transcribe(\"calling_data.m4a\")\n",
    "    full_text = \" \".join([seg.text for seg in segments])\n",
    "    print(\"ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸:\")\n",
    "    print(full_text)\n",
    "\n",
    "    return CallingState(\n",
    "        full_text=full_text,\n",
    "        summary=\"\",\n",
    "        messages=[]\n",
    "    )\n",
    "\n",
    "# 3ï¸âƒ£ ìš”ì•½ ë° ìš”êµ¬ì‚¬í•­ ì •ë¦¬ í•¨ìˆ˜ â†’ State ê°±ì‹ \n",
    "def summarize(state: CallingState) -> CallingState:\n",
    "    load_dotenv()\n",
    "    client = openai.OpenAI()\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    ë‹¤ìŒ ê³ ê°ê³¼ì˜ í†µí™” ë‚´ìš©ì„ ìš”ì•½í•˜ê³ , ê³ ê°ì˜ ìš”êµ¬ì‚¬í•­ì„ ë‹¤ìŒ í•„ë“œë³„ë¡œ ì •ë¦¬í•´ì¤˜:\n",
    "    - ì§€ì—­:\n",
    "    - ë§¤ì²´:\n",
    "    - íƒ€ê²Ÿì¸µ:\n",
    "    - ë¹„ê³  (ë¯¸íŒ… ë‚ ì§œ, ì¶”í›„ ì—°ë½ ë“±):\n",
    "    - ì—°ë½ì²˜:\n",
    "    - ì„±ì‚¬ ì—¬ë¶€:\n",
    "\n",
    "    í†µí™” ë‚´ìš©:\n",
    "    \\\"\\\"\\\"{state['full_text']}\\\"\\\"\\\" \n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"ë„ˆëŠ” ì˜ì—… ë‹´ë‹¹ìì˜ ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ê³ ê°ì˜ ìš”êµ¬ì‚¬í•­ì„ ì •í™•í•˜ê²Œ ì •ë¦¬í•´ì•¼ í•´.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.2\n",
    "    )\n",
    "\n",
    "    summary = response.choices[0].message.content\n",
    "    print(\"ğŸ” ìš”ì•½ ë° ìš”êµ¬ì‚¬í•­ ì •ë¦¬:\")\n",
    "    print(summary)\n",
    "\n",
    "    return CallingState(\n",
    "        full_text=state[\"full_text\"],\n",
    "        summary=summary,\n",
    "        messages=[]  # ë‚˜ì¤‘ì— GPT ë©”ì‹œì§€ ê¸°ë¡ ë„£ìœ¼ë©´ ë¨\n",
    "    )\n",
    "\n",
    "# 4ï¸âƒ£ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
    "state: CallingState = {\"full_text\": \"\", \"summary\": \"\", \"messages\": []}\n",
    "\n",
    "state = transcribe(state)\n",
    "state = summarize(state)\n",
    "\n",
    "print(\"ğŸ—‚ï¸ ìµœì¢… State:\")\n",
    "print(state)\n",
    "\n",
    "# ì´ë¦„, ì´ë©”ì¼, ë‚´ìš©, ìš”êµ¬ì‚¬í•­(ì§€ì—­, ë§¤ì²´, íƒ€ê²Ÿì¸µ), ë©”ëª¨(ë¹„ê³ , ì„±ì‚¬ì—¬ë¶€)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1ï¸âƒ£ Whisperë¡œ ìŒì„± â†’ í…ìŠ¤íŠ¸ ë³€í™˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸:\n",
      " ì•ˆë…•í•˜ì„¸ìš” ì˜¤ê°œê´‘ê³ ëŒ€ í–‰ì‚¬ ì˜¬ë¦¬ì§ˆ êµ¿ì…ë‹ˆë‹¤. í˜¹ì‹œ ì–¸ì–´ë¶€ ë‹´ë‹¹ì ë§ìœ¼ì‹ ê°€ìš”? ë„¤ ë§ìŠµë‹ˆë‹¤.  ë„¤ ì•ˆë…•í•˜ì„¸ìš”. ë‹¤ë¦„ì´ ì•„ë‹ˆë¼ ì´ë²ˆ ì‹ ì œí’ˆ ì¶œì‹œì— ë§ì¶°ì„œ ì €í¬ê°€ í™ëŒ€ ì§€í•˜ì²  ë§¤ì²´ë¥¼ ì œí•œë“œë¦¬ê³ ì í•˜ëŠ”ë° í˜¹ì‹œ ê´€ì‹¬ ìˆìœ¼ì‹¤ê¹Œìš”? í™ëŒ€ê°€ ì–¸ì–´ë¶€ ì£¼ìš” íƒ€ê³„ì¸µì¸ mgì„¸ëŒ€ì™€ ë”± ë§ì„ ê²ƒ ê°™ì•„ì„œìš”.  ì•„ ì €í¬ê°€ ì´ë²ˆì— í™ëŒ€ëŠ” ë§ê³  ì„±ìˆ˜ì˜ íŒŒë²„ìŠ¤í† ë¦¬ ê³„íšì¸ë° í˜¹ì‹œ ì„±ìˆ™ ì¢€ ë§¤ì²´ë„ ìˆë‚˜ìš”? ë„¤ ë¬¼ë¡ ì´ì£ . ì„±ìˆ˜ì—­ ê·¼ì²˜ ë¿ë§Œ ì•„ë‹ˆë¼ ì„±ìˆ˜ ì¹´í˜ ê±°ë¦¬ ì¤‘ì‹¬ìœ¼ë¡œ ì €í¬ê°€ ì—¬ëŸ¬ ë§¤ì²´ë¥¼ ë³´ìœ í•˜ê³  ìˆëŠ”ë° í˜¹ì‹œ ì œê°€ ë¯¸íŒ…ìœ¼ë¡œ ìì„¸í•˜ê²Œ ì„¤ëª…ë“œë ¤ë„ ë ê¹Œìš”? ì£„ì†¡í•œë° ì œê°€ ë¯¸íŒ… ì–´ë¦´ ê²ƒ ê°™ê³ ìš”. ì´ë©œë¡œ ì¼ë‹¨ ì œí•œì„œ ë³´ë‚´ì£¼ì„¸ìš”. ë„¤ ê·¸ëŸ¼ ì €í¬ í†µí•© ì˜¤ê°œ ê´‘ê³  ì œí•œì„œì™€ í•¨ê»˜ ì„±ìˆ˜ íŒŒë²…ì„ ë§ì¶˜ ì œí•œì„œ ë”°ë¡œ ë³´ë‚´ë“œë¦¬ê² ìŠµë‹ˆë‹¤.  í˜¹ì‹œ ë‹´ë‹´ìë¶„ ì„±í•¨ê³¼ ì´ë©”ì¼ ì•Œ ìˆ˜ ìˆì„ê¹Œìš”? ì œ ì´ë¦„ì€ ì´ íš¨ì •ì´ê³ ìš”. ì´ë©”ì¼ì€ sgsgk113 ê³¨ë±…ì´ ìŠ¤í¬ë¼ë‹¤ì»´ì…ë‹ˆë‹¤. ë„¤ sgsgk113 ê³¨ë±…ì´ skal8.coì— ë§ìœ¼ì‹œì£ ? ì˜¤ëŠ˜ ì¤‘ìœ¼ë¡œ ë§¤ì¼ ë“œë¦¬ê² ìŠµë‹ˆë‹¤. ê°ì‚¬í•©ë‹ˆë‹¤. ë„¤ ê°ì‚¬í•©ë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "\n",
    "model = WhisperModel(\"base\")  # í•„ìš”í•˜ë©´ small/medium/large ì‚¬ìš© ê°€ëŠ¥\n",
    "segments, info = model.transcribe(\"calling_data.m4a\")\n",
    "\n",
    "full_text = \" \".join([seg.text for seg in segments])\n",
    "print(\"ğŸ“ ì¸ì‹ëœ í…ìŠ¤íŠ¸:\")\n",
    "print(full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ìš”ì•½ ë° ìš”êµ¬ì‚¬í•­ ì •ë¦¬:\n",
      "- ì§€ì—­: ì„±ìˆ˜\n",
      "- ë§¤ì²´: ì„±ìˆ˜ì—­ ê·¼ì²˜ ë° ì„±ìˆ˜ ì¹´í˜ ê±°ë¦¬ ì¤‘ì‹¬ì˜ ë‹¤ì–‘í•œ ë§¤ì²´\n",
      "- íƒ€ê²Ÿì¸µ: MGì„¸ëŒ€\n",
      "- ë¹„ê³  (ë¯¸íŒ… ë‚ ì§œ, ì¶”í›„ ì—°ë½ ë“±): ê³ ê°ì´ ë¯¸íŒ… ëŒ€ì‹  ì´ë©”ì¼ë¡œ ì œì•ˆì„œë¥¼ ë°›ê¸°ë¥¼ ì›í•¨. ì˜¤ëŠ˜ ì¤‘ìœ¼ë¡œ ì´ë©”ì¼ ë°œì†¡ ì˜ˆì •.\n",
      "- ì—°ë½ì²˜: ì´ë©”ì¼ - sgsgk113@skal8.co\n",
      "- ì„±ì‚¬ ì—¬ë¶€: ì œì•ˆì„œ ë°œì†¡ í›„ ê²°ì •ë  ì˜ˆì • (í˜„ì¬ ì„±ì‚¬ ì—¬ë¶€ ë¯¸í™•ì •)\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = openai.OpenAI()  # ìµœì‹ ë²„ì „: client ê°ì²´ ìƒì„±\n",
    "\n",
    "def summarize_and_extract(text):\n",
    "    prompt = f\"\"\"\n",
    "    ë‹¤ìŒ ê³ ê°ê³¼ì˜ í†µí™” ë‚´ìš©ì„ ìš”ì•½í•˜ê³ , ê³ ê°ì˜ ìš”êµ¬ì‚¬í•­ì„ ë‹¤ìŒ í•„ë“œë³„ë¡œ ì •ë¦¬í•´ì¤˜:\n",
    "    - ì§€ì—­:\n",
    "    - ë§¤ì²´:\n",
    "    - íƒ€ê²Ÿì¸µ:\n",
    "    - ë¹„ê³  (ë¯¸íŒ… ë‚ ì§œ, ì¶”í›„ ì—°ë½ ë“±):\n",
    "    - ì—°ë½ì²˜:\n",
    "    - ì„±ì‚¬ ì—¬ë¶€:\n",
    "\n",
    "    í†µí™” ë‚´ìš©:\n",
    "    \\\"\\\"\\\"{text}\\\"\\\"\\\" \n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"ë„ˆëŠ” ì˜ì—… ë‹´ë‹¹ìì˜ ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ê³ ê°ì˜ ìš”êµ¬ì‚¬í•­ì„ ì •í™•í•˜ê²Œ ì •ë¦¬í•´ì•¼ í•´.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.2\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# full_text ì‚¬ìš©\n",
    "summary = summarize_and_extract(full_text)\n",
    "\n",
    "print(\"ğŸ” ìš”ì•½ ë° ìš”êµ¬ì‚¬í•­ ì •ë¦¬:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“ CLOVA ìµœì¢… ë³€í™˜ ê²°ê³¼:\n",
      "ì•ˆë…•í•˜ì„¸ìš” ì˜¥ì™¸ê´‘ê³  ëŒ€í–‰ì‚¬ ì˜¬ë¦¬ ì§ˆ ê²ƒì…ë‹ˆë‹¤ í˜¹ì‹œ ì–´ëŠ ë¶€ ë‹´ë‹¹ì ë§ìœ¼ì‹ ê°€ìš” ë„¤ ë§ìŠµë‹ˆë‹¤ ë„¤ ì•ˆë…•í•˜ì„¸ìš” ë‹¤ë¦„ì´ ì•„ë‹ˆë¼ ì´ë²ˆ ì‹ ì œí’ˆ ì¶œì‹œì— ë§ì¶°ì„œ ì €í¬ê°€ í™ëŒ€ ì§€í•˜ì²  ë§¤ì²´ë¥¼ ëŒ€ì²´í•œ ë“œë¦¬ê³ ì í•˜ëŠ”ë° í˜¹ì‹œ ê´€ì‹¬ ìˆìœ¼ì‹¤ê¹Œìš” í™ëŒ€ê°€ ì–´ëŠ ë¶€ì¡±ì˜ íƒ€ê²Ÿ ì¸µì—” ì— ì§€ ì„¸ëŒ€ì™€ ë”± ë§ì„ ê²ƒ ê°™ì•„ì„œìš” ì–´ì„œ ì´ê±° ì´ë²ˆì— í™ëŒ€ëŠ” ë§ê³  ìƒì„¸ íŒì—… ìŠ¤í† ì–´ ë¦¬ë‰´ì–¼ ê³„íšì¸ë° í˜¹ì‹œ ì„ ìˆ˜ì´Œ ë§¤ì²´ë„ ìˆë‚˜ìš” ë„¤ ë¬¼ë¡ ì´ì£  ì„±ìˆ˜ì—­ ê·¼ì²˜ë¿ë§Œ ì•„ë‹ˆë¼ ìƒìˆ˜ ì¹´í˜ê±°ë¦¬ ì¤‘ì‹¬ìœ¼ë¡œ ì €í¬ê°€ ì—¬ëŸ¬ ë§¤ì²´ë¥¼ ë³´ìœ í•˜ê³  ìˆëŠ”ë° í˜¹ì‹œ ì œê°€ ë¯¸íŒ…ìœ¼ë¡œ ìì„¸í•˜ê²Œ ì„¤ëª… ë“œë ¤ë„ ë ê¹Œìš” ì£„ì†¡í•œë° ì œê°€ ë¯¸íŒ… ì˜¤ë¥¼ ê²ƒ ê°™ê³ ìš” ì´ë©œë¡œ ìˆë˜ ìµœ í•œì„œ ë³´ë‚´ì£¼ì„¸ìš” ë„¤ ê·¸ëŸ¼ ì €í¬ í†µí•© ì˜¥ì™¸ ê´‘ê³  ì œì•ˆì„œì™€ í•¨ê»˜ ì„±ìˆ˜ íŒì—…ì„ ë§ˆì¹œ ìì—°ì„œ ë”°ë¡œ ë³´ë‚´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤ í˜¹ì‹œ ìì—°ì„œ ë”°ë¡œ ë³´ë‚´ ë“œë¦¬ê² ìŠµë‹ˆë‹¤ í˜¹ì‹œ ë‹´ë‹¹ì ë¶„ ì„±í•¨ê³¼ ì´ë©”ì¼ ì•Œìˆ˜ ìˆì„ê¹Œìš” ì•„ ì œ ì´ë¦„ì€ ì´í˜¸ì •ì´ì•¼ ê·¸ ì´ë©”ì¼ì€ sg ì—ìŠ¤ì§€ ì¼€ì´ ì¼ì‚° ê³¨ë±…ì´ ë‹·ì»´ì…ë‹ˆë‹¤ ë‚´ sg ì—ìŠ¤ì§€ ì¼€ì´ 1213 ê³¨ë±…ì´ skl ì  ì‹œì˜¤ì— ë§ìœ¼ì‹œì£  ì˜¤ëŠ˜ì¤‘ìœ¼ë¡œ ë©”ì¼ ë“œë¦¬ê² ìŠµë‹ˆë‹¤ ê°ì‚¬í•©ë‹ˆë‹¤ ê°ì‚¬í•©ë‹ˆë‹¤\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# ë„¤ì´ë²„ í´ë¼ìš°ë“œ í”Œë«í¼ì—ì„œ ë°œê¸‰ë°›ì€ í‚¤\n",
    "CLOVA_API_URL = \"https://naveropenapi.apigw.ntruss.com/recog/v1/stt\"\n",
    "ACCESS_KEY = \"\"\n",
    "SECRET_KEY = \"\"\n",
    "\n",
    "def compress_audio(input_file, output_file, format=\"wav\", bitrate=\"64k\"):\n",
    "    \"\"\"ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì••ì¶•í•˜ì—¬ í¬ê¸°ë¥¼ ì¤„ì…ë‹ˆë‹¤.\"\"\"\n",
    "    try:\n",
    "        audio = AudioSegment.from_file(input_file)\n",
    "        audio.export(output_file, format=format, bitrate=bitrate)\n",
    "        print(f\"âœ… íŒŒì¼ ì••ì¶• ì™„ë£Œ: {output_file} (ì›ë³¸ í¬ê¸°ì˜ ì•½ {os.path.getsize(output_file)/os.path.getsize(input_file)*100:.1f}%)\")\n",
    "        return output_file\n",
    "    except Exception as e:\n",
    "        print(f\"â— íŒŒì¼ ì••ì¶• ì‹¤íŒ¨: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "def clova_speech_to_text(file_path):\n",
    "    headers = {\n",
    "        \"X-NCP-APIGW-API-KEY-ID\": ACCESS_KEY,\n",
    "        \"X-NCP-APIGW-API-KEY\": SECRET_KEY,\n",
    "        \"Content-Type\": \"application/octet-stream\"\n",
    "    }\n",
    "\n",
    "    params = {\n",
    "        \"lang\": \"Kor\"  # í•œêµ­ì–´ ì½”ë“œ\n",
    "    }\n",
    "\n",
    "    with open(file_path, 'rb') as f:\n",
    "        audio_data = f.read()\n",
    "\n",
    "    response = requests.post(CLOVA_API_URL, headers=headers, params=params, data=audio_data)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        result_json = response.json()\n",
    "\n",
    "        # ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "        text = result_json.get('text', '')\n",
    "        return text\n",
    "\n",
    "    else:\n",
    "        print(f\"â— CLOVA API ìš”ì²­ ì‹¤íŒ¨: {response.status_code}\")\n",
    "        print(response.text)\n",
    "        return None\n",
    "\n",
    "def process_multiple_audios(file_list):\n",
    "    \"\"\"ì—¬ëŸ¬ ê°œì˜ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ë³€í™˜í•˜ê³  ê²°ê³¼ë¥¼ í•©ì¹¨.\"\"\"\n",
    "    full_transcript = \"\"\n",
    "    for file_path in file_list:\n",
    "        # print(f\"ğŸ” ë³€í™˜ ì¤‘: {file_path}\")\n",
    "        text = clova_speech_to_text(file_path)\n",
    "        # print(f\"âœ… ë³€í™˜ ê²°ê³¼: {text}\\n\")\n",
    "        full_transcript += text + \" \"\n",
    "    return full_transcript.strip()\n",
    "\n",
    "# âœ… ë¶ˆëŸ¬ì˜¬ ì˜¤ë””ì˜¤ íŒŒì¼ë“¤\n",
    "audio_files = [\"calling_data1.wav\", \"calling_data2.wav\"]  # íŒŒì¼ëª…ì€ ì‹¤ì œ íŒŒì¼ì— ë§ê²Œ ìˆ˜ì •\n",
    "\n",
    "transcript = process_multiple_audios(audio_files)\n",
    "\n",
    "print(\"\\nğŸ“ CLOVA ìµœì¢… ë³€í™˜ ê²°ê³¼:\")\n",
    "print(transcript)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2ï¸âƒ£ GPTë¡œ ìš”ì•½ ë° ìš”êµ¬ì‚¬í•­ ì •ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ìš”ì•½ ë° ìš”êµ¬ì‚¬í•­ ì •ë¦¬:\n",
      "- ì§€ì—­: í™ëŒ€, ì„±ìˆ˜\n",
      "- ë§¤ì²´: í™ëŒ€ ì§€í•˜ì² , ì„±ìˆ˜ì—­ ê·¼ì²˜ ë° ìƒìˆ˜ ì¹´í˜ê±°ë¦¬ ì¤‘ì‹¬ì˜ ì˜¥ì™¸ê´‘ê³  ë§¤ì²´\n",
      "- íƒ€ê²Ÿì¸µ: MZ ì„¸ëŒ€\n",
      "- ë¹„ê³  (ë¯¸íŒ… ë‚ ì§œ, ì¶”í›„ ì—°ë½ ë“±): ë¯¸íŒ… ëŒ€ì‹  ì´ë©”ì¼ë¡œ ì œì•ˆì„œ ìš”ì²­, ì˜¤ëŠ˜ ì¤‘ìœ¼ë¡œ ì´ë©”ì¼ ë°œì†¡ ì˜ˆì •\n",
      "- ì—°ë½ì²˜: ì´ë©”ì¼ - sg1213@skl.co.kr\n",
      "- ì„±ì‚¬ ì—¬ë¶€: ì œì•ˆì„œ ì´ë©”ì¼ ë°œì†¡ í›„ ê²°ì • ì˜ˆì •\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "client = openai.OpenAI()  # ìµœì‹ ë²„ì „: client ê°ì²´ ìƒì„±\n",
    "\n",
    "def summarize_and_extract(text):\n",
    "    prompt = f\"\"\"\n",
    "    ë‹¤ìŒ ê³ ê°ê³¼ì˜ í†µí™” ë‚´ìš©ì„ ìš”ì•½í•˜ê³ , ê³ ê°ì˜ ìš”êµ¬ì‚¬í•­ì„ ë‹¤ìŒ í•„ë“œë³„ë¡œ ì •ë¦¬í•´ì¤˜:\n",
    "    - ì§€ì—­:\n",
    "    - ë§¤ì²´:\n",
    "    - íƒ€ê²Ÿì¸µ:\n",
    "    - ë¹„ê³  (ë¯¸íŒ… ë‚ ì§œ, ì¶”í›„ ì—°ë½ ë“±):\n",
    "    - ì—°ë½ì²˜:\n",
    "    - ì„±ì‚¬ ì—¬ë¶€:\n",
    "\n",
    "    í†µí™” ë‚´ìš©:\n",
    "    \\\"\\\"\\\"{text}\\\"\\\"\\\" \n",
    "    \"\"\"\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"ë„ˆëŠ” ì˜ì—… ë‹´ë‹¹ìì˜ ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ê³ ê°ì˜ ìš”êµ¬ì‚¬í•­ì„ ì •í™•í•˜ê²Œ ì •ë¦¬í•´ì•¼ í•´.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ],\n",
    "        temperature=0.2\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "# full_text ì‚¬ìš©\n",
    "summary = summarize_and_extract(transcript)\n",
    "\n",
    "print(\"ğŸ” ìš”ì•½ ë° ìš”êµ¬ì‚¬í•­ ì •ë¦¬:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdb4168d92d9486d9dc9251fe5847fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/2.31k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c7f8207fae04aa085ac5221c5ecde2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.27G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at kresnik/wav2vec2-large-xlsr-korean were not used when initializing Wav2Vec2ForCTC: ['wav2vec2.encoder.pos_conv_embed.conv.weight_v', 'wav2vec2.encoder.pos_conv_embed.conv.weight_g']\n",
      "- This IS expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing Wav2Vec2ForCTC from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at kresnik/wav2vec2-large-xlsr-korean and are newly initialized: ['wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original0', 'wav2vec2.encoder.pos_conv_embed.conv.parametrizations.weight.original1']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2382dfeaf2a342508ccf05a87e096558",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/161 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2174a769c2c4d84ac06c3fe7cf6b774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/18.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a19f10aac4754a23a857af5e38de21b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/214 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì–‘ëƒ ì„¸ì–´ ì˜¤ê° ê´‘ê³   í–‰ì‚¬ ì˜¬ë¦¬ì§€ ê¾¸ì…ë‹ˆë‹¤ í˜¹ì‹œ ì–´í›„ë¶€ ë‹´ë‹¹ì ë§ˆì§€ì‹ ê°€ìš” ë‚´ë°›ìŠµë‹ˆë‹¤ ë‚œëƒì„¸ ë‹¤ë¦„ ì•„ë‹ˆë¼ ì´ë²ˆ ì‹ ì œí’ˆ ì¶œì‹œì— ë§ì¶°ì„œ ì €í¬ê°€ í™ëŒ€ ì§€í•˜ì²  ë§¤ì²´ë¥¼ ì œì•ˆë“¤ì´ ê³ ì í•˜ëŠ”ë° í˜¹ì‹œ ê´€ì‹¬ ë¯¸ìŠ¤ì‹¤ê¹Œìš” í™ëŒ€ê°€ ì˜¨í›„ë¶€ ìš” íƒ€ê²Œì±…ì¸ ë Œì§€ì„¸ëŒ€ì™€ ë”± ë§ˆì„ ê²ƒ ê°™ì•˜ì„œìš”  ì†Œì´ê°€ ì´ë²ˆì„ í™ëŒ€ëŠ” ë¬¼ê³  ì„±ìˆ  í¼ë¸”ìŠ¤í† ë¦¬ì—´ ê³„íšì¸ë° í˜¹ì‹œ í™ìŠµìª½ ë§¤íŠ¸ëœë‚  ë‚´ ë¬¼ë¡ ì´ì ìƒì†Œì˜€ ê·¼ì²˜ë¿ë§Œ ì•„ë‹ˆë¼ ì„ ìˆ˜ ì¹´í˜ê±°ë¦¬ ì¤‘ì‹¬ìœ¼ë¡œ ì €í¬ê°€ ì—¬ëŸ¬ ë§¤ì²´ë¥¼ ë³´ìœ í•˜ê³  ìˆëŠ”ë° í˜¹ì‹œ ì œê°€ ë¯¸íŒ…ìœ¼ë¡œ ìì„¸í•˜ê²Œ ì„¤ëª…ë“¤ì–´ë„ ë ê¹Œìš”  ìµœì†Œì›ë“¤ ì œë¹„íŒ…ì˜¤ë¥¼ ë¶€ê¾¸ìš” ì´ë¯¸ë¡œìˆë˜ ì œì•ˆì†Œ ë³´ë‚´ ì£¼ì„¸ë„¤ ê·¸ëŸ¼ ì €í¬ í†µí•© ì˜¤ë°± ê´‘ê³  ì œì•ˆì†Œì™€ í•¨ê»˜ ìƒìŠµ íŒŒë²•ì„ ê°™ì¶˜ ì œì•ˆì„œ ë”°ë¡œ ë³´ë‚´ë“¤ë¦¬ê² ìŠµë‹ˆí˜¹ì‹œ ë‹¹ë‹¹ìë³¸ ì„±í•œê³¼ ì´ë¯¸ ì•Œ ìˆ˜ ìˆì„ê¹Œìš” ì œ ì´ë¦„ì€ ì´í›„ ì •ì´ê³ ìš” ì´ë¯¸ì€ ë©”ë ˆìŠ¤ì¼€ì´ì´ ì‚° ê³¨ë°±ì´ ìŠ¤í”Œë˜ë”ì»´ì…ë‹ˆì‹œì§€ì‹œì§€ì¼€ì´ì¼ë¦¬ìƒ ê³¨ë°±ì´ ì—ìŠ¤ì¼€ì´ì—ì´ì—˜ì—ì´ ì©œ ì‹œì˜¤ì— ë§ˆì§€ì‹œì ì˜¤ëŠ˜ ì¢…ìœ¼ë¡œ ë§¤ ë“¤ë¦¬ê² ìŠµë‹ˆë‹¤ ê°ì‚¬í•©ë‹ˆë‹¤ ë¶„ì‚°ë‹ˆë‹¤\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# ìŒì„±ì—ì„œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜\n",
    "transcriber = pipeline(\"automatic-speech-recognition\", model=\"kresnik/wav2vec2-large-xlsr-korean\")\n",
    "audio_file = \"calling_data.wav\"\n",
    "result = transcriber(audio_file)\n",
    "print(result[\"text\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OoHMarketingSales",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
