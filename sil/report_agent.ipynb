{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\envs\\OoHMarketingSales\\Lib\\site-packages\\transformers\\utils\\generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "from typing import TypedDict, Optional\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import StateGraph\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import mysql.connector\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from docx import Document\n",
    "import pandas as pd\n",
    "import os\n",
    "from docx.shared import Inches\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ğŸ” ìƒíƒœ ì •ì˜ ---\n",
    "class ProposalState(TypedDict, total=False):\n",
    "    brand_name: Optional[str]\n",
    "    brand_info: Optional[str]\n",
    "    client_needs: Optional[str]\n",
    "    recent_issues: Optional[str]\n",
    "    sales_status: Optional[str]\n",
    "    recommended_media: Optional[str]\n",
    "    previous_campaigns: Optional[str]\n",
    "    proposal_text: Optional[str]\n",
    "    proposal_file_path: Optional[str]\n",
    "    media_info: list\n",
    "\n",
    "AgentState = ProposalState"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Administrator\\anaconda3\\envs\\OoHMarketingSales\\Lib\\site-packages\\huggingface_hub\\file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# --- .env ì—ì„œ OPENAI API í‚¤ ë¶ˆëŸ¬ì˜¤ê¸° ---\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", openai_api_key=openai_api_key)\n",
    "\n",
    "# --- HuggingFace ê¸°ë°˜ ì„ë² ë”© í´ë˜ìŠ¤ ---\n",
    "class BERTSentenceEmbedding:\n",
    "    def __init__(self, model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "    def embed_documents(self, texts):\n",
    "        return [self._embed(text) for text in texts]\n",
    "\n",
    "    def embed_query(self, text):\n",
    "        return self._embed(text)\n",
    "\n",
    "    def _embed(self, text):\n",
    "        inputs = self.tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**inputs)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :]  # (batch_size, hidden_size)\n",
    "        return cls_embedding.squeeze(0).cpu().numpy()\n",
    "\n",
    "# --- embedding_function ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ---\n",
    "embedding_function = BERTSentenceEmbedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ğŸ—„ï¸ Tool êµ¬ì„± (ì—¬ê¸°ì„œëŠ” ì˜ˆì‹œ Stub í˜•íƒœë¡œ Tool ì„¤ì •) ---\n",
    "# ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œëŠ” ì•„ë˜ Toolë“¤ì„ LangChain Toolkitìœ¼ë¡œ êµ¬í˜„\n",
    "\n",
    "def db_query_tool(query: str):\n",
    "    import mysql.connector\n",
    "    from dotenv import load_dotenv\n",
    "    import os\n",
    "\n",
    "    load_dotenv()  # .env íŒŒì¼ ë¡œë“œ\n",
    "\n",
    "    host = os.getenv(\"DB_HOST\")\n",
    "    user = os.getenv(\"DB_USER\")\n",
    "    password = os.getenv(\"DB_PASSWORD\")\n",
    "    database = os.getenv(\"DB_NAME\")\n",
    "\n",
    "    conn = mysql.connector.connect(\n",
    "        host=host,\n",
    "        user=user,\n",
    "        password=password,\n",
    "        database=database\n",
    "    )\n",
    "    cursor = conn.cursor(dictionary=True)\n",
    "    cursor.execute(query)\n",
    "    results = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    return results\n",
    "\n",
    "\n",
    "def web_search_tool(query: str) -> str:\n",
    "    return f\"[WEB SEARCH RESULT for: {query}]\"\n",
    "\n",
    "def vectordb_search_tool(query: str, collection_name: str, top_k: int = 3) -> str:\n",
    "    vectorstore = Chroma(\n",
    "        collection_name=collection_name,\n",
    "        embedding_function=embedding_function\n",
    "    )\n",
    "    results = vectorstore.similarity_search(query, k=top_k)\n",
    "\n",
    "    combined_results = []\n",
    "    for doc in results:\n",
    "        content = doc.page_content\n",
    "\n",
    "        content_lines = [f\"- {line.strip()}\" for line in content.split(\",\")]\n",
    "        content_formatted = \"\\n\".join(content_lines)\n",
    "\n",
    "        image_url = doc.metadata.get(\"execution_image_url\", \"\")\n",
    "        if image_url.startswith(\"/images/\"):\n",
    "            image_url = \"../\" + image_url.lstrip(\"/\")\n",
    "        elif image_url == \"\":\n",
    "            image_url = \"[ì´ë¯¸ì§€ ì—†ìŒ]\"\n",
    "\n",
    "        content_with_image = f\"{content_formatted}\\n[ì´ë¯¸ì§€ ë³´ê¸°]({image_url})\"\n",
    "        combined_results.append(content_with_image)\n",
    "\n",
    "    return \"\\n\\n---\\n\\n\".join(combined_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… HuggingFace ì„ë² ë”©ìœ¼ë¡œ 72ê°œ ë¬¸ì„œ ì €ì¥ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# --- ChromaDBì— campaign_media ë°ì´í„° ì˜¬ë¦¬ê¸° (ìµœì´ˆ 1íšŒ) ---\n",
    "csv_path = \"../data/campaign_media.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "def row_to_text(row):\n",
    "    return (\n",
    "        f\"ìº í˜ì¸ ID: {row['campaign_id']}, \"\n",
    "        f\"ë§¤ì²´ ID: {row['media_id']}, \"\n",
    "        f\"ì‹œì‘ì¼: {row['start_date']}, \"\n",
    "        f\"ì¢…ë£Œì¼: {row['end_date']}, \"\n",
    "        f\"êµ¬ì¢Œ ìˆ˜: {row['slot_count']}, \"\n",
    "        f\"ì§‘í–‰ ê°€ê²©: {row['executed_price']}, \"\n",
    "        f\"ì§„í–‰ ìƒíƒœ: {row['campaign_media_status']}\"\n",
    "    )\n",
    "\n",
    "texts = []\n",
    "metadatas = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    texts.append(row_to_text(row))\n",
    "    metadatas.append({\"execution_image_url\": row[\"execution_image_url\"]})\n",
    "\n",
    "# --- ë¬¸ì„œ ë¶„í•  ---\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = splitter.create_documents(texts, metadatas=metadatas)\n",
    "\n",
    "# --- Chroma ì»¬ë ‰ì…˜ì— ì €ì¥ (HuggingFace ì„ë² ë”© ì‚¬ìš©) ---\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=docs,\n",
    "    embedding=embedding_function,  # âœ… embedding_functionìœ¼ë¡œ ìˆ˜ì •\n",
    "    collection_name=\"campaign_media_chroma_hf\"  # âœ… ìƒˆ ì»¬ë ‰ì…˜ ì´ë¦„\n",
    ")\n",
    "\n",
    "print(f\"âœ… HuggingFace ì„ë² ë”©ìœ¼ë¡œ {len(docs)}ê°œ ë¬¸ì„œ ì €ì¥ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_brand_and_sales_logs(brand_name: str):\n",
    "    load_dotenv()\n",
    "    conn = mysql.connector.connect(\n",
    "        host=os.getenv(\"DB_HOST\"),\n",
    "        user=os.getenv(\"DB_USER\"),\n",
    "        password=os.getenv(\"DB_PASSWORD\"),\n",
    "        database=os.getenv(\"DB_NAME\")\n",
    "    )\n",
    "    cursor = conn.cursor(dictionary=True)\n",
    "\n",
    "    # 1ï¸âƒ£ ë¸Œëœë“œ ì •ë³´ ê°€ì ¸ì˜¤ê¸°\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT * FROM brand WHERE brand_name = %s\n",
    "    \"\"\", (brand_name,))\n",
    "    brand_info = cursor.fetchone()\n",
    "\n",
    "    if not brand_info:\n",
    "        cursor.close()\n",
    "        conn.close()\n",
    "        return None, None\n",
    "\n",
    "    brand_id = brand_info[\"brand_id\"]\n",
    "\n",
    "    # 2ï¸âƒ£ ìµœì‹  sales_log ì •ë³´ ê°€ì ¸ì˜¤ê¸° (brand_id ê¸°ì¤€)\n",
    "    cursor.execute(\"\"\"\n",
    "        SELECT * FROM sales_log \n",
    "        WHERE brand_id = %s \n",
    "        ORDER BY contact_time DESC \n",
    "        LIMIT 1\n",
    "    \"\"\", (brand_id,))\n",
    "    latest_sales_log = cursor.fetchone()\n",
    "\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "    return brand_info, latest_sales_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from decimal import Decimal\n",
    "\n",
    "def decimal_default(obj):\n",
    "    if isinstance(obj, Decimal):\n",
    "        return float(obj)\n",
    "    raise TypeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Node 1: ë¸Œëœë“œ ì •ë³´ + ê³ ê° ìš”êµ¬ì‚¬í•­ ë¶„ì„ ---\n",
    "def analyze_brand_and_needs(state: ProposalState):\n",
    "    brand_name = state[\"brand_name\"]\n",
    "\n",
    "    brand_info, latest_sales_log = query_brand_and_sales_logs(brand_name)\n",
    "\n",
    "    if not brand_info:\n",
    "        raise ValueError(f\"ë¸Œëœë“œ '{brand_name}' ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    # ìµœì‹  ê³ ê° ìš”êµ¬ì‚¬í•­ ìš”ì•½ ê°€ì ¸ì˜¤ê¸°\n",
    "    client_needs = latest_sales_log[\"client_needs_summary\"] if latest_sales_log else \"ìµœê·¼ ê³ ê° ìš”êµ¬ì‚¬í•­ ì •ë³´ ì—†ìŒ\"\n",
    "\n",
    "    # ë¸Œëœë“œ ì´ìŠˆ ë° ìƒíƒœ ì •ë³´ ì¶”ê°€ (LLM í”„ë¡¬í”„íŠ¸ì— ë„ì›€ë¨)\n",
    "    recent_issues = brand_info.get(\"recent_brand_issues\") or \"ë¸Œëœë“œ ì´ìŠˆ ì •ë³´ ì—†ìŒ\"\n",
    "    sales_status = brand_info.get(\"sales_status\") or \"ìƒíƒœ ì •ë³´ ì—†ìŒ\"\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"brand_info\": brand_info,\n",
    "        \"client_needs\": client_needs,\n",
    "        \"recent_issues\": recent_issues,\n",
    "        \"sales_status\": sales_status\n",
    "    }\n",
    "\n",
    "# --- Node 2: ìœ ì‚¬ ì§‘í–‰ ì‚¬ë¡€ ì¡°íšŒ ì‚¬ì§„ ì •ë³´ ë¨¼ì €---\n",
    "def retrieve_previous_campaigns(state: ProposalState):\n",
    "    client_needs = state.get(\"client_needs\") or \"ì˜¥ì™¸ ê´‘ê³  ì§‘í–‰ ì‚¬ë¡€\"\n",
    "\n",
    "    collection_name = \"campaign_media_chroma_hf\"  # ë²¡í„°ìŠ¤í† ì–´ ì»¬ë ‰ì…˜ ì´ë¦„\n",
    "    similar_cases = vectordb_search_tool(client_needs, collection_name)\n",
    "\n",
    "    return {**state, \"previous_campaigns\": similar_cases}\n",
    "\n",
    "# --- Node 3: ë§¤ì²´ ì¶”ì²œ ë° ë§¤ì¹­ ìœ ì‚¬ ì§‘í–‰ ì‚¬ë¡€ì™€ ê¸°ì¡´ ë§¤ì²´ í†µí•©í•´ì„œ MZ íŒ¨í‚¤ì§€ ë§¤ì²´ ì—¬ëŸ¬ê°œ ---\n",
    "# media, ì›¹ê²€ìƒ‰?!\n",
    "def recommend_media(state: ProposalState):\n",
    "    client_needs = state.get(\"client_needs\") or \"\"\n",
    "    db_results = db_query_tool(\"SELECT * FROM media WHERE quantity > 0;\")\n",
    "\n",
    "    if not db_results or len(db_results) == 0:\n",
    "        raise ValueError(\"ì‚¬ìš© ê°€ëŠ¥í•œ ë§¤ì²´ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "    media_info = db_results  # ì´ê±¸ stateì— ë„˜ê¹€\n",
    "\n",
    "    media_json = json.dumps(db_results, ensure_ascii=False, default=lambda o: float(o) if isinstance(o, Decimal) else str(o))\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        ë‹¹ì‹ ì€ ì˜¥ì™¸ ê´‘ê³  ì „ë¬¸ ëŒ€í–‰ì‚¬ì˜ ì „ëµ ê¸°íšìì…ë‹ˆë‹¤.\n",
    "\n",
    "        ë‹¤ìŒ ë¸Œëœë“œì˜ ê³ ê° ìš”êµ¬ì‚¬í•­ê³¼ ìœ ì‚¬ ì§‘í–‰ ì‚¬ë¡€ë¥¼ ê³ ë ¤í•˜ì—¬ ê°€ì¥ ì í•©í•œ ì˜¥ì™¸ ê´‘ê³  ë§¤ì²´ 3ê°€ì§€ë¥¼ ì¶”ì²œí•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "\n",
    "        - ë¸Œëœë“œ ê³ ê° ìš”êµ¬ì‚¬í•­: {state.get('client_needs')}\n",
    "        - ìœ ì‚¬ ì§‘í–‰ ì‚¬ë¡€ ìš”ì•½: {state.get('previous_campaigns')}\n",
    "\n",
    "        ë‹¤ìŒì€ ì‚¬ìš© ê°€ëŠ¥í•œ ë§¤ì²´ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤:\n",
    "        {media_json}\n",
    "\n",
    "        ê°ê° ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ ì¶”ì²œí•˜ì‹­ì‹œì˜¤:\n",
    "        1. ëŒ€í–‰ì‚¬ ì…ì¥ì—ì„œ ê°€ì¥ ì „ëµì ìœ¼ë¡œ ì¶”ì²œí•˜ëŠ” ë§¤ì²´ (íš¨ê³¼ì™€ ì¸ì§€ë„ê°€ ë†’ìŒ)\n",
    "        2. ê°€ê²©ì ìœ¼ë¡œ ì €ë ´í•˜ë©´ì„œ íš¨ê³¼ì ì¸ ë§¤ì²´\n",
    "        3. ê¸°íƒ€ ì¶”ì²œí•  ë§Œí•œ ë§¤ì²´ í•œ ê°€ì§€\n",
    "\n",
    "        ê° í›„ë³´ ë§¤ì²´ì— ëŒ€í•´ ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•˜ì‹­ì‹œì˜¤:\n",
    "        - ë§¤ì²´ëª…: {{ë§¤ì²´ëª…}}\n",
    "        - ì˜ˆìƒ ì§‘í–‰ ê°€ê²©: {{ê¸ˆì•¡}} ì›\n",
    "        - ì˜ˆìƒ ì§‘í–‰ ê¸°ê°„: {{ê¸°ê°„}}\n",
    "        - ì˜ˆìƒ ë…¸ì¶œ ë¹ˆë„: {{ë…¸ì¶œ ë¹ˆë„}}\n",
    "        - ì¶”ì²œ ì´ìœ : {{ì´ìœ }}\n",
    "\n",
    "        **ë§¤ì²´ëª…: ì´ë¼ëŠ” í‚¤ì›Œë“œë¥¼ ê¼­ í¬í•¨í•˜ê³  ê° ë§¤ì²´ëŠ” ì¤„ë°”ê¿ˆí•˜ì—¬ êµ¬ë¶„í•˜ì„¸ìš”.**\n",
    "        \"\"\"\n",
    "\n",
    "    recommendation = llm.invoke(prompt)\n",
    "    recommendation_text = recommendation.content  # ë¬¸ìì—´ë¡œ ë³€í™˜\n",
    "    \n",
    "    return {\n",
    "        **state,\n",
    "        \"recommended_media\": recommendation_text,\n",
    "        \"media_info\": media_info\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Node 4: ì œì•ˆì„œ ìƒì„± (Word íŒŒì¼ í¬í•¨) ---\n",
    "def generate_proposal(state: ProposalState):\n",
    "    import datetime\n",
    "    import re\n",
    "    from docx import Document\n",
    "    from docx.shared import Inches\n",
    "    from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "    doc = Document()\n",
    "    doc.add_heading(f\"{state['brand_name']} ì˜¥ì™¸ ê´‘ê³  ì œì•ˆì„œ\", level=1)\n",
    "    doc.add_paragraph(\"\") \n",
    "\n",
    "    # --- 1. ê³ ê°ì‚¬ ì •ë³´ ---\n",
    "    doc.add_heading(\"1. ê³ ê°ì‚¬ ì •ë³´\", level=2)\n",
    "    brand_info = state[\"brand_info\"]\n",
    "\n",
    "    # brand_infoê°€ dict í˜•íƒœë¼ë©´:\n",
    "    if isinstance(brand_info, dict):\n",
    "        for key, value in brand_info.items():\n",
    "            doc.add_paragraph(f\"- {key}: {value}\")\n",
    "    else:\n",
    "        # CSVì²˜ëŸ¼ í•œ ì¤„ë¡œ ë“¤ì–´ì™”ì„ ê²½ìš° â†’ í‚¤:ê°’ í˜•íƒœë¡œ ì¤„ë°”ê¿ˆ\n",
    "        lines = re.split(r\",|\\t\", brand_info)\n",
    "        for line in lines:\n",
    "            if ':' in line:\n",
    "                doc.add_paragraph(f\"- {line.strip()}\")\n",
    "            elif line.strip():\n",
    "                doc.add_paragraph(f\"- {line.strip()}\")\n",
    "\n",
    "    # --- 2. ìº í˜ì¸ ëª©í‘œ ---\n",
    "    doc.add_paragraph(\"\") \n",
    "    doc.add_heading(\"2. ìº í˜ì¸ ëª©í‘œ\", level=2)\n",
    "    client_needs = state[\"client_needs\"]\n",
    "\n",
    "    # ì‰¼í‘œë¡œ êµ¬ë¶„ â†’ ë¬¸ì¥ë³„ë¡œ ì¶œë ¥\n",
    "    for item in re.split(r\",|Â·|â€¢\", client_needs):\n",
    "        if item.strip():\n",
    "            doc.add_paragraph(f\"- {item.strip()}\")\n",
    "\n",
    "    # --- 3. ìœ ì‚¬ ì§‘í–‰ ì‚¬ë¡€ ---\n",
    "    doc.add_heading(\"3. ìœ ì‚¬ ì§‘í–‰ ì‚¬ë¡€\", level=2)\n",
    "    previous_campaigns = state[\"previous_campaigns\"]\n",
    "\n",
    "    cases = previous_campaigns.split(\"\\n\\n---\\n\\n\")\n",
    "    filtered_cases = []\n",
    "    for idx, case in enumerate(cases, start=1):\n",
    "        if \"ì‚¬ë¡€ 3\" in case:\n",
    "            continue  # ì‚¬ë¡€ 3 ì œì™¸\n",
    "\n",
    "        # ì´ë¯¸ì§€ URL ì¶”ì¶œ\n",
    "        image_url = None\n",
    "        image_match = re.search(r\"\\[ì´ë¯¸ì§€ ë³´ê¸°\\]\\((.*?)\\)\", case)\n",
    "        if image_match:\n",
    "            image_url = image_match.group(1).strip()\n",
    "\n",
    "        # í…ìŠ¤íŠ¸ì—ì„œ [ì´ë¯¸ì§€ ë³´ê¸°] ë¶€ë¶„ ì‚­ì œ\n",
    "        case_text = re.sub(r\"\\[ì´ë¯¸ì§€ ë³´ê¸°\\]\\(.*?\\)\", \"\", case).strip()\n",
    "        filtered_cases.append((f\"- ì‚¬ë¡€ {idx}\\n{case_text}\", image_url))\n",
    "\n",
    "    # âœ… 3í–‰ 2ì—´ì§œë¦¬ í‘œ ìƒì„± (í–‰ = ì‚¬ë¡€ ê°œìˆ˜, ì—´ = 2)\n",
    "    table = doc.add_table(rows=len(filtered_cases), cols=2)\n",
    "    table.style = 'Table Grid'\n",
    "\n",
    "    for row_idx, (case_text, image_url) in enumerate(filtered_cases):\n",
    "        # ì™¼ìª½ ì…€: ì‚¬ë¡€ ë‚´ìš©\n",
    "        table.cell(row_idx, 0).text = case_text\n",
    "\n",
    "        # ì˜¤ë¥¸ìª½ ì…€: ì´ë¯¸ì§€ ë˜ëŠ” í…ìŠ¤íŠ¸\n",
    "        cell_image = table.cell(row_idx, 1)\n",
    "        if image_url and image_url.endswith((\".jpg\", \".png\")):\n",
    "            try:\n",
    "                run = cell_image.paragraphs[0].add_run()\n",
    "                run.add_picture(image_url, width=Inches(2.5))\n",
    "            except Exception as e:\n",
    "                cell_image.text = f\"ì´ë¯¸ì§€ ì‚½ì… ì‹¤íŒ¨ ({e})\"\n",
    "        else:\n",
    "            cell_image.text = \"ì´ë¯¸ì§€ ì—†ìŒ\"\n",
    "\n",
    "    # --- 4. ì¶”ì²œë§¤ì²´ ë° ì§‘í–‰ê³„íš ---\n",
    "    doc.add_paragraph(\"\") \n",
    "    doc.add_heading(\"4. ì¶”ì²œë§¤ì²´ ë° ì§‘í–‰ê³„íš\", level=2)\n",
    "\n",
    "    recommended_media = state[\"recommended_media\"]\n",
    "    if hasattr(recommended_media, \"content\"):\n",
    "        recommended_media_text = recommended_media.content\n",
    "    else:\n",
    "        recommended_media_text = recommended_media\n",
    "\n",
    "    media_rows = state.get(\"media_info\", [])\n",
    "    media_image_map = {row[\"media_name\"].strip().lower(): row[\"image_day_url\"] for row in media_rows}\n",
    "\n",
    "    media_blocks = []\n",
    "    current_block = \"\"\n",
    "    for line in recommended_media_text.split(\"\\n\"):\n",
    "        # â­ ì œëª©ì˜ \"**\" ì œê±° (block ì¶”ê°€ ì „ ì²˜ë¦¬)\n",
    "        clean_line = re.sub(r\"\\*+\", \"\", line.strip())\n",
    "        if re.match(r\"^\\d+\\.\", clean_line):\n",
    "            if current_block:\n",
    "                media_blocks.append(current_block.strip())\n",
    "            current_block = clean_line\n",
    "        elif clean_line:\n",
    "            current_block += \"\\n\" + clean_line\n",
    "    if current_block:\n",
    "        media_blocks.append(current_block.strip())\n",
    "\n",
    "    table = doc.add_table(rows=len(media_blocks), cols=2)\n",
    "    table.style = 'Table Grid'\n",
    "\n",
    "    for idx, block in enumerate(media_blocks):\n",
    "        # ë§¤ì²´ëª… ì¶”ì¶œ\n",
    "        name_match = re.search(r\"ë§¤ì²´ëª…\\s*[:ï¼š]\\s*(.+)\", block)\n",
    "        if name_match:\n",
    "            media_name = name_match.group(1).strip()\n",
    "        else:\n",
    "            name_match = re.search(r\"^\\d+\\.\\s*(.+)\", block)\n",
    "            media_name = name_match.group(1).strip() if name_match else \"ì¶”ì²œ ë§¤ì²´\"\n",
    "\n",
    "        media_name_clean = media_name.replace(\"*\", \"\").strip().lower()\n",
    "        image_url = media_image_map.get(media_name_clean)\n",
    "        if image_url and image_url.startswith(\"/images/\"):\n",
    "            image_url = \"../images/\" + image_url[len(\"/images/\"):]\n",
    "        # ì™¼ìª½: ì„¤ëª…\n",
    "        table.cell(idx, 0).text = block\n",
    "        # ì˜¤ë¥¸ìª½: ì´ë¯¸ì§€\n",
    "        cell_image = table.cell(idx, 1)\n",
    "        if image_url and image_url.endswith((\".jpg\", \".png\")):\n",
    "            try:\n",
    "                run = cell_image.paragraphs[0].add_run()\n",
    "                run.add_picture(image_url, width=Inches(3))\n",
    "            except Exception as e:\n",
    "                cell_image.text = f\"ì´ë¯¸ì§€ ì‚½ì… ì‹¤íŒ¨ ({e})\"\n",
    "        else:\n",
    "            cell_image.text = \"ì´ë¯¸ì§€ ì—†ìŒ\"\n",
    "\n",
    "    # --- 5. ê²°ë¡  (LLM ì‚¬ìš©) ---\n",
    "    doc.add_paragraph(\"\") \n",
    "    doc.add_heading(\"5. ê²°ë¡ \", level=2)\n",
    "\n",
    "    # LLM í”„ë¡¬í”„íŠ¸\n",
    "    prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    ë¸Œëœë“œëª…: {brand_name}\n",
    "    ìº í˜ì¸ ëª©í‘œ: {client_needs}\n",
    "    ì¶”ì²œ ë§¤ì²´: {recommended_media}\n",
    "\n",
    "    ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìº í˜ì¸ì˜ ê²°ë¡  ë¶€ë¶„ì„ ì‘ì„±í•˜ì„¸ìš”.\n",
    "    \"\"\")\n",
    "    chain = prompt | llm\n",
    "    conclusion = chain.invoke(state).content\n",
    "\n",
    "    doc.add_paragraph(conclusion)\n",
    "\n",
    "    now = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    file_name = f\"{state['brand_name']}_ì œì•ˆì„œ_{now}.docx\"\n",
    "    doc.save(file_name)\n",
    "\n",
    "    return {**state, \"proposal_text\": conclusion, \"proposal_file_path\": file_name}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ğŸ”— ê·¸ë˜í”„ êµ¬ì„± ---\n",
    "graph = StateGraph(ProposalState)\n",
    "\n",
    "graph.add_node(\"AnalyzeBrandAndNeeds\", analyze_brand_and_needs)\n",
    "graph.add_node(\"RecommendMedia\", recommend_media)\n",
    "graph.add_node(\"RetrievePreviousCampaigns\", retrieve_previous_campaigns)\n",
    "graph.add_node(\"GenerateProposal\", generate_proposal)\n",
    "\n",
    "graph.set_entry_point(\"AnalyzeBrandAndNeeds\")\n",
    "graph.add_edge(\"AnalyzeBrandAndNeeds\", \"RetrievePreviousCampaigns\")\n",
    "graph.add_edge(\"RetrievePreviousCampaigns\", \"RecommendMedia\")\n",
    "graph.add_edge(\"RecommendMedia\", \"GenerateProposal\")\n",
    "graph.set_finish_point(\"GenerateProposal\")\n",
    "\n",
    "proposal_graph = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ìµœì¢… ì œì•ˆì„œ:\n",
      "\n",
      "ìº í˜ì¸ ê²°ë¡ :\n",
      "\n",
      "ìœ ë‹ˆí´ë¡œì½”ë¦¬ì•„ì˜ 2025ë…„ 5ì›” ê°•ë‚¨ ë° í™ëŒ€ ì§€ì—­ ë””ì§€í„¸ ì‚¬ì´ë‹ˆì§€ ìº í˜ì¸ì€ ê°€ì¡±ì„ íƒ€ê²Ÿìœ¼ë¡œ í•˜ì—¬ ì„±ê³µì ì¸ ë¸Œëœë“œ ì¸ì§€ë„ë¥¼ í™•ë¦½í•˜ê¸° ìœ„í•œ ì „ëµì  ì ‘ê·¼ì„ ì·¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. ê°€ì¥ íš¨ê³¼ì ì´ê³  ì¸ì§€ë„ê°€ ë†’ì€ ë§¤ì²´ë¡œëŠ” ê°•ë‚¨ì—­ M-Plaza ë¯¸ë””ì–´íƒ€ì›Œë¥¼ ì¶”ì²œë“œë¦¬ë©°, ì´ëŠ” 20-40ëŒ€ ì§ì¥ì¸ ë° ì‡¼í•‘ê°ì„ ì§ì ‘ì ìœ¼ë¡œ íƒ€ê²ŸíŒ…í•  ìˆ˜ ìˆëŠ” ìµœì ì˜ ìœ„ì¹˜ì— ìˆìœ¼ë©°, ë†’ì€ ìœ ë™ì¸êµ¬ë¡œ ì¸í•´ ë¸Œëœë“œ ë©”ì‹œì§€ì˜ ë„ë‹¬ ë²”ìœ„ë¥¼ ê·¹ëŒ€í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
      "\n",
      "ë”ë¶ˆì–´, ì˜ˆì‚°ì ì¸ ì¸¡ë©´ì„ ê³ ë ¤í•œ í™ìµëŒ€í•™êµ ì• ë””ì§€í„¸ ë²„ìŠ¤ì‰˜í„°ë¥¼ ë§¤ì²´ë¡œ ì„ ì •í•¨ìœ¼ë¡œì¨, 20ëŒ€ ì Šì€ì¸µê³¼ ì§€ì—­ ìƒê¶Œ ì´ìš©ìë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ê³µëµí•  ìˆ˜ ìˆìœ¼ë©°, ì €ë ´í•œ ê°€ê²© ëŒ€ë¹„ íš¨ìœ¨ì ì¸ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.\n",
      "\n",
      "ê¸°íƒ€ ë³´ì™„ ë§¤ì²´ë¡œ ì œì•ˆë“œë¦° í™ëŒ€ì…êµ¬ì—­ ë””ì§€í„¸ìŠ¤í¬ë¦°ì€ 10-30ëŒ€ ëŒ€í•™ìƒ ë° ê´€ê´‘ê°ì„ ì£¼ìš” íƒ€ê²Ÿìœ¼ë¡œ í•˜ë©°, í˜„ì¥ ë…¸ì¶œë¿ ì•„ë‹ˆë¼ SNS ì±„ë„ì„ í†µí•œ ë°”ì´ëŸ´ íš¨ê³¼ë„ ê¸°ëŒ€í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ë‹¤ì–‘í•œ ë§¤ì²´ì˜ í™œìš©ì€ ìœ ë‹ˆí´ë¡œì½”ë¦¬ì•„ì˜ ìº í˜ì¸ ëª©í‘œ ë‹¬ì„±ì— ê¸°ì—¬í•  ê²ƒì…ë‹ˆë‹¤.\n",
      "\n",
      "ì´ ìº í˜ì¸ì„ í†µí•´ ìœ ë‹ˆí´ë¡œì½”ë¦¬ì•„ê°€ íƒ€ê²Ÿ ì†Œë¹„ìì¸µê³¼ì˜ ì—°ê²°ì„ ê°•í™”í•˜ê³ , ê°•ë‚¨ê³¼ í™ëŒ€ ì§€ì—­ì—ì„œì˜ ë¸Œëœë“œ ì¡´ì¬ê°ì„ í™•ê³ íˆ í•¨ìœ¼ë¡œì¨ ë¸Œëœë“œ ì¸ì§€ë„ë¥¼ í•œì¸µ ë” ë†’ì¼ ìˆ˜ ìˆì„ ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë©ë‹ˆë‹¤.\n",
      "ğŸ“„ ì œì•ˆì„œ Word íŒŒì¼ ê²½ë¡œ: ìœ ë‹ˆí´ë¡œì½”ë¦¬ì•„_ì œì•ˆì„œ_20250508_180458.docx\n"
     ]
    }
   ],
   "source": [
    "# --- ğŸš€ ì‹¤í–‰ ì˜ˆì‹œ ---\n",
    "initial_state = {\n",
    "    \"brand_name\": \"ìœ ë‹ˆí´ë¡œì½”ë¦¬ì•„\",\n",
    "}\n",
    "\n",
    "final_state = proposal_graph.invoke(initial_state)\n",
    "\n",
    "print(\"âœ… ìµœì¢… ì œì•ˆì„œ:\\n\")\n",
    "print(final_state[\"proposal_text\"])\n",
    "print(f\"ğŸ“„ ì œì•ˆì„œ Word íŒŒì¼ ê²½ë¡œ: {final_state['proposal_file_path']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OoHMarketingSales",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
